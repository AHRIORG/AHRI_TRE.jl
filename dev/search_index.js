var documenterSearchIndex = {"docs":
[{"location":"api/#Functions","page":"API","title":"Functions","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"","category":"page"},{"location":"api/#Function-Specifications","page":"API","title":"Function Specifications","text":"","category":"section"},{"location":"api/#AHRI_TRE._strip_html-Tuple{AbstractString}","page":"API","title":"AHRI_TRE._strip_html","text":"_strip_html(text::AbstractString) -> String\n\nRemove HTML tags, script/style blocks, and decode a few common entities. Collapse whitespace to single spaces and trim ends. Used to clean REDCap rich-text labels before persisting them as variable descriptions.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.add_study_domain!-Tuple{DataStore, Study, Domain}","page":"API","title":"AHRI_TRE.add_study_domain!","text":"add_study_domain!(store::DataStore, study::Study, domain::Domain)\n\nAdd a domain to a study by inserting a record into the study_domains table.\n\n'store' is the DataStore object containing the database connection.\n'study' is the Study object containing the study_id.\n'domain' is the Domain object containing the domain_id.\n\nIf the combination of (studyid, domainid) already exists, it does nothing. If the domain is not already in the study.domains list, it adds it to the study.domains vector.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.add_transformation_input-Tuple{DataStore, Int64, Base.UUID}","page":"API","title":"AHRI_TRE.add_transformation_input","text":"add_transformation_input(store::DataStore, transformation_id::Int, version_id::UUID)::Nothing\n\nAdd a transformation input to the transformation_inputs table.\n\nstore: The DataStore object containing connection details for the datastore.\ntransformation_id: The ID of the transformation to which the input belongs.\nversion_id: The UUID of the asset version that is the input to the transformation.\n\nThis function will insert a new record into the transformation_inputs table linking the transformation to the asset version.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.add_transformation_input-Tuple{DataStore, Transformation, AssetVersion}","page":"API","title":"AHRI_TRE.add_transformation_input","text":"add_transformation_input(store::DataStore, transformation::Transformation, version::AssetVersion)::Nothing\n\nAdd a transformation input to the transformation_inputs table using Transformation and AssetVersion objects.\n\nstore: The DataStore object containing connection details for the datastore.\ntransformation: The Transformation object containing the transformation_id.\nversion: The AssetVersion object containing the version_id.\n\nThis function checks that both the transformation and version have valid IDs before calling the lower-level function.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.add_transformation_output-Tuple{DataStore, Int64, Base.UUID}","page":"API","title":"AHRI_TRE.add_transformation_output","text":"add_transformation_output(store::DataStore, transformation_id::Int, version_id::UUID)::Nothing\n\nAdd a transformation output to the transformation_outputs table.\n\nstore: The DataStore object containing connection details for the datastore.\ntransformation_id: The ID of the transformation to which the output belongs.\nversion_id: The UUID of the asset version that is the output of the transformation.\n\nThis function will insert a new record into the transformation_outputs table linking the transformation to the asset version.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.add_transformation_output-Tuple{DataStore, Transformation, AssetVersion}","page":"API","title":"AHRI_TRE.add_transformation_output","text":"add_transformation_output(store::DataStore, transformation::Transformation, version::AssetVersion)::Nothing\n\nAdd a transformation output to the transformation_outputs table using Transformation and AssetVersion objects.\n\nstore: The DataStore object containing connection details for the datastore.\ntransformation: The Transformation object containing the transformation_id.\nversion: The AssetVersion object containing the version_id.\n\nThis function checks that both the transformation and version have valid IDs before calling the lower-level function.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.attach_datafile-Tuple{DataStore, AssetVersion, AbstractString, String}","page":"API","title":"AHRI_TRE.attach_datafile","text":"attach_datafile(store::DataStore, assetversion::AssetVersion, file_path::AbstractString, edam_format::String;\ncompress::Bool=false, encrypt::Bool=false)::DataFile\n\nAttach a data file to an existing asset version in the TRE datastore.\n\nstore: The DataStore object containing connection details for the datastore.\nassetversion: The AssetVersion object to which the data file will be attached.\nfile_path: The full path including the file name to the file.\nedam_format: The EDAM format of the data file (e.g., \"http://edamontology.org/format_3752\" for a csv file).\ncompress: Whether the file should be compressed (default is false).   If true, the file will be compressed using zstd, and the existing file will be replaced with the compressed version.\nencrypt: Whether the file should be encrypted (default is false). NOT currently implemented\n\nThis function does not copy the file, it only registers it in the TRE datastore. It assumes the file is already in the data lake and creates a DataFile object associated with the given asset version.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.attach_datafile-Tuple{DataStore, Study, String, AbstractString, String}","page":"API","title":"AHRI_TRE.attach_datafile","text":"attach_datafile(store::DataStore, study::Study, asset_name::String,\nfile_path::AbstractString, edam_format::String; description::Union{String,Missing}=missing, compress::Bool=false, encrypt::Bool=false)::DataFile\n\nAttach a data file that is already in the data lake to the TRE datastore.\n\nstore: The DataStore object containing connection details for the datastore.\nstudy: The Study object to associate with the data file.\nasset_name: The name of the asset to which the data file will be attached. Must comply with xsd:NCName restrictions.\nfile_path: The full path including the file name to the file.\nedam_format: The EDAM format of the data file (e.g., \"http://edamontology.org/format_3752\" for a csv file).\ndescription: A description of the data file (default is missing).\ncompress: Whether the file should be compressed (default is false).   If true, the file will be compressed using zstd, and the existing file will be replaced with the compressed version.\nencrypt: Whether the file should be encrypted (default is false). NOT currently implemented\n\nThis function does not copy the file, it only registers it in the TRE datastore. It assumes the file is already in the data lake and creates an Asset object with a base version\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.caller_file_runtime","page":"API","title":"AHRI_TRE.caller_file_runtime","text":"caller_file_runtime()\n\nReturn the file path of the script that called this function at runtime.   'level' indicates how many levels up the call stack to go (default 1 = immediate caller).\n\n\n\n\n\n","category":"function"},{"location":"api/#AHRI_TRE.closedatastore-Tuple{DataStore}","page":"API","title":"AHRI_TRE.closedatastore","text":"closedatastore(store::DataStore)\n\nClose the connections in a DataStore object\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.convert_missing_to_string!-Tuple{DataFrames.DataFrame}","page":"API","title":"AHRI_TRE.convert_missing_to_string!","text":"convert_missing_to_string!(df::DataFrame)\n\nIf the column type is Missing, convert the column eltype to Union{String, Missing}.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.create_asset","page":"API","title":"AHRI_TRE.create_asset","text":"create_asset(store::DataStore, study::Study, name::String, type::String, description::Union{Missing,String}=missing)::Asset\n\nCreate a new asset in the TRE datastore and the base version of the asset.\n\nstore: The DataStore object containing connection details for the datastore.\nstudy: The Study object to associate with the asset.\nname: The name of the asset. Will be coherced to xsd:NCName format.\ntype: The type of the asset, either \"dataset\" or \"file\".\ndescription: An optional description of the asset (default is missing).\n\nReturns the created Asset object with its asset_id and the first version.\n\n\n\n\n\n","category":"function"},{"location":"api/#AHRI_TRE.create_dataset_meta-Tuple{DataStore, Study, String, String, DataFile}","page":"API","title":"AHRI_TRE.create_dataset_meta","text":"create_dataset_meta(store::DataStore, study::Study, dataset_name::String, description::String, datafile::DataFile)::DataSet\n\nCreate a new dataset metadata object from an EAV data file.\n\n'store' is the DataStore object containing the database connection.\n'study' is the Study object to associate with the dataset.\n'dataset_name' is the name of the dataset to create.\n'description' is a description for the dataset.\n'datafile' is the DataFile object representing the EAV data file that the dataset is derived from.\n\nThis function creates a new dataset asset and version, collects variable metadata from the EAV data file, and returns a DataSet object containing the dataset metadata. It assumes the EAV data is stored in a csv table with columns: record, field_name\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.createassets-Tuple{DBInterface.Connection}","page":"API","title":"AHRI_TRE.createassets","text":"createassets(conn::DBInterface.Connection)\n\nCreate tables to record data assets, rows, data and links to the transformations that use/created the assets A digital asset is a dataset or file that is stored in the TRE datalake. The assetversions table tracks different versions of the assets, with a version label and note.  An asset can have multiple versions, and the latest version is flagged by the islatest flag set as TRUE. The datasets table is a type of asset that is linked to the assetversions table and managed through the ducklake extension. The datafiles table stores references to files in the data lake, with metadata such as compression, encryption, storage URI, format, and digest. The transformationinputs and transformationoutputs tables link transformations to the asset versions they use or produce. The datasetvariables table links datasets to the variables (columns) they contain, representing the schema of the dataset. The dataassetentities table links assets to entity instances, allowing for tracking which entities are associated with specific assets.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.createdatabase-Tuple{DBInterface.Connection}","page":"API","title":"AHRI_TRE.createdatabase","text":"createdatabase(conn::DBInterface.Connection; replace=false)\n\nBuild the TRE schema objects in an existing PostgreSQL database connection. This function no longer creates or drops the physical database; that responsibility has been moved to createdatastore (see refactor 2b). The DuckDB/ducklake metadata database creation code remains untouched in createdatastore.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.createdatastore-Tuple{DataStore}","page":"API","title":"AHRI_TRE.createdatastore","text":"createdatastore(store::DataStore; superuser::String=\"postgres\", superpwd::String=\"\", port::Int=5432)\n\nCreate or replace a PostgreSQL database for the TRE datastore, including the datalake if specified. This function creates a PostgreSQL database with the specified name and user credentials, and optionally creates a data lake using the DuckDb extension ducklake.     store::DataStore: The DataStore object containing connection details for the datastore and datalake databases.     superuser::String: The superuser name for PostgreSQL (default is \"postgres\").     superpwd::String: The superuser password for PostgreSQL (default is empty).     port::Int: The port number for the PostgreSQL server (default is 5432 NB: ONLY USE THIS FUNCTION IN DEVELOPMENT OR TESTING ENVIRONMENTS,     as it will drop the existing database, lake and all its contents.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.createentities-Tuple{DBInterface.Connection}","page":"API","title":"AHRI_TRE.createentities","text":"createentities(conn)\n\nCreate tables to store entities, entity relations, entity instances, and relation instances. Entities represent individuals, households, or other entities in the TRE. Entity relations represent relationships between entities, such as family or household relationships. Entity instances represent specific instances of entities in a study, allowing for tracking of entities across studies.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.createmapping-Tuple{DBInterface.Connection}","page":"API","title":"AHRI_TRE.createmapping","text":"createmapping(conn::DBInterface.Connection)\n\nCreate the table required for variable mapping. This table is used to map variables from one instrument to another. The table is created in the database provided as an argument. The variable mapping is based on the PyCrossVA approach.\n\nThe relationship to the PyCrossVA configuration file columns:\n\nNew Column Name = destinationid - the variableid of the new column\nNew Column Documentation = Stored in the variable table\nstudy Column ID = fromid - the variableid of the study variable\nstudy Column Documentation = will be in the variables table\nRelationship = operator - the operator to be used to create the new variable\nCondition = operants - the operants to be used with the operator\nPrerequisite = prerequisiteid - the variableid of the prerequisite variable\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.createstudies-Tuple{DBInterface.Connection}","page":"API","title":"AHRI_TRE.createstudies","text":"createstudies(conn::DBInterface.Connection)\n\nCreates tables to record a study and associated site/s for deaths contributed to the TRE (PostgreSQL version)\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.createtransformations-Tuple{DBInterface.Connection}","page":"API","title":"AHRI_TRE.createtransformations","text":"createtransformations(conn::DBInterface.Connection)\n\nCreate tables to record data transformations and data ingests\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.createvariables-Tuple{DBInterface.Connection}","page":"API","title":"AHRI_TRE.createvariables","text":"createvariables(conn)\n\nCreate tables to record value types, variables and vocabularies\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.dataset_to_arrow-Tuple{DataStore, AHRI_TRE.DataSet, String}","page":"API","title":"AHRI_TRE.dataset_to_arrow","text":"dataset_column(db::DBInterface.Connection, dataset::DataSet, variable::Variable)\n\ndataset_to_arrow(db, dataset, datapath)\n\nSave a dataset in the arrow format\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.dataset_to_csv-Tuple{DataStore, AHRI_TRE.DataSet, String}","page":"API","title":"AHRI_TRE.dataset_to_csv","text":"dataset_to_csv(store::DataStore, dataset::DataSet, outputdir::String; replace::Bool=false, compress=false)\n\nSave a dataset in compressed csv format\n\nstore: The DataStore object containing the datastore and datalake connections.\ndataset: The DataSet object to be saved as CSV.\noutputdir: The directory where the CSV file will be saved.\nreplace: If true, will overwrite existing files (default is false).\ncompress: If true, will save the CSV file in compressed .zst format (default is false).\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.dataset_to_dataframe-Tuple{DataStore, AHRI_TRE.DataSet}","page":"API","title":"AHRI_TRE.dataset_to_dataframe","text":"dataset_to_dataframe(store::DataStore, dataset::DataSet)::DataFrame\n\nRetrieve a dataset from store.lake and return as a DataFrame\n\nstore: The DataStore object containing the datastore and datalake connections.\ndataset: The DataSet object to be retrieved. NB version must be set.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.dataset_variables-Tuple{DBInterface.Connection, AHRI_TRE.DataSet}","page":"API","title":"AHRI_TRE.dataset_variables","text":"dataset_variables(db::DBInterface.Connection, dataset)::AbstractDataFrame\n\nReturn the list of variables in a dataset\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.emptydir-Tuple{AbstractString}","page":"API","title":"AHRI_TRE.emptydir","text":"emptydir(path; create=true, retries=3, wait=0.2)\n\nEnsure path exists (if create=true), then remove all files/subdirs inside it, keeping path itself. Retries briefly to tolerate transient files.\n\nSafety: refuses to operate on the filesystem root \"/\".\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.ensure_vocabulary!-Tuple{Any, String, String, Any}","page":"API","title":"AHRI_TRE.ensure_vocabulary!","text":"ensure_vocabulary!(db, vocab_name::String, description::String,\n                   items::Vector{NamedTuple{(:value,:code,:description),Tuple{Int,String,Union{String,Missing}}}}) -> Int\n\nCreates or reuses a vocabulary by name, and (re)loads items idempotently. Returns vocabulary_id.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.file_uri_to_path-Tuple{AbstractString}","page":"API","title":"AHRI_TRE.file_uri_to_path","text":"file_uri_to_path(uri::AbstractString) -> String\n\nConvert a file:// URI to a local filesystem path (Windows or Unix). Handles:\n\nfile:///C:/...        -> C:... (Windows)\nfile://server/share   -> \\server\\share (Windows UNC)\nfile:///home/me/...   -> /home/me/... (Unix)\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_asset-Tuple{DataStore, Base.UUID}","page":"API","title":"AHRI_TRE.get_asset","text":"get_asset(store::DataStore, asset_id::UUID)::Union{Asset,Nothing}\n\nReturn an Asset object by its asset_id in the specified DataStore.\n\n'store' is the DataStore object containing the database connection.\n'asset_id' is the UUID of the asset to search for.\n\nIf no asset is found, it returns nothing. If an asset is found, it returns an Asset object with its versions populated.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_asset-Tuple{DataStore, Study, String}","page":"API","title":"AHRI_TRE.get_asset","text":"get_asset(store::DataStore, study::Study, name::String)::Union{Asset,Nothing}\n\nReturn an Asset object by its name in the specified study.\n- 'store' is the DataStore object containing the database connection.\n- 'study' is the Study object to search in.\n- 'name' is the name of the asset to search for.\nIf no asset is found, it returns `nothing`.\nIf an asset is found, it returns an Asset object\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_assetversions-Tuple{DataStore, Asset}","page":"API","title":"AHRI_TRE.get_assetversions","text":"get_assetversions(store::DataStore, asset::Asset)::Vector{AssetVersion}\n\nReturn a vector of AssetVersion objects for the specified asset.\n\n'store' is the DataStore object containing the database connection.\n'asset' is the Asset object for which to retrieve versions.\n\nIf no versions are found, it returns an empty vector.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_datafile_meta-Tuple{DataStore, AssetVersion}","page":"API","title":"AHRI_TRE.get_datafile_meta","text":"get_datafile_meta(store::DataStore, assetversion::AssetVersion)::Union{DataFile,Nothing}\n\nGet metadata for a DataFile associated with the specified AssetVersion.\n\nstore: The DataStore object containing connection details for the datastore.\nassetversion: The AssetVersion object for which to retrieve the DataFile metadata.\n\nIf no DataFile is found, it returns nothing.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_datasetname-Tuple{AHRI_TRE.DataSet}","page":"API","title":"AHRI_TRE.get_datasetname","text":"get_datasetname(dataset::DataSet; include_schema::Bool=false)::String\n\nReturn a valid dataset name for the dataset, optionally including the schema (study) name.\n\ndataset: The DataSet object for which to generate the name.\ninclude_schema: If true, includes the schema (study) name as a prefix to the dataset name (default is false).\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_domain-Tuple{DataStore, AbstractString}","page":"API","title":"AHRI_TRE.get_domain","text":"get_domain(store::DataStore, name::AbstractString; uri::Union{Nothing,String}=nothing)::Union{Domain,Nothing}\n\nReturn a Domain object by its name (and optional URI) in the specified DataStore. If uri is nothing, it searches for the domain by name only. If uri is provided, it searches for the domain by both name and URI. If no domain is found, it returns nothing. If a domain is found, it returns a Domain object with the domain_id, name, uri, and description.\n\n'store' is the DataStore object containing the database connection.\n'name' is the name of the domain to search for.\n'uri' is an optional URI to further filter the domain search.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_eav_variables-Tuple{DataStore, DataFile}","page":"API","title":"AHRI_TRE.get_eav_variables","text":"get_eav_variables(store::DataStore, datafile::DataFile)::Vector{Variable}\n\nReturn a vector of Variable objects representing the EAV variables in the specified DataFile.\n\n'store' is the DataStore object containing the database connection.\n'datafile' is the DataFile object for which to retrieve EAV variables.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_entity-Tuple{DataStore, Int64, String}","page":"API","title":"AHRI_TRE.get_entity","text":"get_entity(store::DataStore, domain_id::Int, name::String)::Union{Entity,Nothing}\n\nReturn an Entity object by its name in the specified domain.\n\n'store' is the DataStore object containing the database connection.\n'domain_id' is the ID of the domain to search in.\n'name' is the name of the entity to search for.\n\nIf no entity is found, it returns nothing.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_entityrelation-Tuple{DataStore, Int64, String}","page":"API","title":"AHRI_TRE.get_entityrelation","text":"get_entityrelation(store::DataStore, domain_id::Int, name::String)::Union{EntityRelation,Nothing}\n\nReturn an EntityRelation object by its name in the specified domain.\n\n'store' is the DataStore object containing the database connection.\n'domain_id' is the ID of the domain to search in.\n'name' is the name of the entity relation to search for.\n\nIf no entity relation is found, it returns nothing. If an entity relation is found, it returns an EntityRelation object\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_latest_version-Tuple{Asset}","page":"API","title":"AHRI_TRE.get_latest_version","text":"get_latest_version(asset::Asset)::Union{AssetVersion,Nothing}\n\nReturn the latest AssetVersion for the specified asset.\n\n'asset' is the Asset object for which to retrieve the latest version.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_latest_version-Tuple{DataStore, Base.UUID}","page":"API","title":"AHRI_TRE.get_latest_version","text":"get_latest_version(store::DataStore, asset_id::UUID)::Union{AssetVersion,Nothing}\n\nReturn the latest AssetVersion for the specified asset_id in the DataStore.\n\n'store' is the DataStore object containing the database connection.\n'asset_id' is the UUID of the asset for which to retrieve the latest version.\n\nIf no latest version is found, it returns nothing.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_namedkey-Tuple{DBInterface.Connection, Any, Any, Any}","page":"API","title":"AHRI_TRE.get_namedkey","text":"get_namedkey(db::DBInterface.Connection, table, key, keycol)\n\nReturn the integer key from table table in column keycol (keycol must be a Symbol) for key with name key\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_study-Tuple{DataStore, AbstractString}","page":"API","title":"AHRI_TRE.get_study","text":"get_study(store::DataStore, name::AbstractString)::Union{Study,Nothing}\n\nReturn a Study object by its name in the specified DataStore.\n\n'store' is the DataStore object containing the database connection.\n'name' is the name of the study to search for.\n\nIf no study is found, it returns nothing. If a study is found, it returns a Study object\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_studyid-Tuple{DataStore, AbstractString}","page":"API","title":"AHRI_TRE.get_studyid","text":"get_studyid(db::DBInterface.Connection, name)\n\nReturn the source_id of source name, returns missing if source doesn't exist\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_table-Tuple{DBInterface.Connection, String}","page":"API","title":"AHRI_TRE.get_table","text":"get_table(conn::DBInterface.Connection, table::String)::AbstractDataFrame\n\nRetrieve table table as a DataFrame from conn\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_variable-Tuple{DBInterface.Connection, Int64}","page":"API","title":"AHRI_TRE.get_variable","text":"get_variable(db::DBInterface.Connection, variable_id::Int)\n\nReturns the entry of variable with variable_id\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_variable_id-Tuple{DBInterface.Connection, Any, Any}","page":"API","title":"AHRI_TRE.get_variable_id","text":"get_variable_id(db::DBInterface.Connection, domain, name)\n\nReturns the `variable_id` of variable named `name` in domain with id `domain`\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_vocabulary-Tuple{DataStore, Int64}","page":"API","title":"AHRI_TRE.get_vocabulary","text":"get_vocabulary(store::DataStore, vocabulary_id::Int)::Union{Vocabulary,Nothing}\n\nReturn a Vocabulary object by its vocabulary_id in the specified DataStore.\n\n'store' is the DataStore object containing the database connection.\n'vocabulary_id' is the ID of the vocabulary to retrieve.\n\nIf no vocabulary is found, it returns nothing. If a vocabulary is found, it returns a Vocabulary object with its items populated.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.git_commit_info","page":"API","title":"AHRI_TRE.git_commit_info","text":"git_commit_info(dir::AbstractString = @__DIR__; short::Bool = true, script_path::AbstractString = @__FILE__)\n\nReturn version control information about the currently executing script for use in transformations.\n\ndir: The directory to search for the git repository (default is the directory of the current script).\nshort: Whether to return a short commit hash (default is true, returns first 7 characters of the hash).\nscript_path: The path to the script being executed (default is the current script file).\n\nReturns a tuple with:\n\nrepo_url: The URL of the git repository (or nothing if not found).\ncommit: The commit hash (or nothing if not found).\nscript_relpath: The relative path of the script from the repository root (or nothing if not found).\n\nThis function normalizes SSH remotes to HTTPS format. If the script is not in a git repository, it returns nothing for all fields.\n\n\n\n\n\n","category":"function"},{"location":"api/#AHRI_TRE.ingest_redcap_project-Tuple{DataStore, AbstractString, AbstractString, Study, Domain}","page":"API","title":"AHRI_TRE.ingest_redcap_project","text":"ingest_redcap_project(api_url::AbstractString, api_token::AbstractString, study::Study, domain::Domain)\n\nRetrieves the REDCap project metadata and add the project variables to the TRE datastore. Downloads the REDCap project records in EAV format to a csv file and saves it to the data lake and creates an ingest transformation. Transforms the csv file from EAV (long) format to wide format dataset and registers the dataset in the TRE datastore.\n\napi_url: The URL of the REDCap API endpoint.\napi_token: The API token for the REDCap project.\nstudy: The Study object to associate with the REDCap project. \ndomain: The Domain object to associate with the REDCap project.\nvocabulary_prefix: The prefix for the vocabulary used in the REDCap project (default is \"REDCap\").\nforms: A vector of form names to include in the REDCap project (default is empty, meaning all forms).\nfields: A vector of field names to include in the REDCap project (default is empty, meaning all fields).\n\nReturns the DataFile object representing the ingested REDCap project data.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.initstudytypes-Tuple{}","page":"API","title":"AHRI_TRE.initstudytypes","text":"initstudytypes()\n\nDefault study types\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.initvalue_types-Tuple{}","page":"API","title":"AHRI_TRE.initvalue_types","text":"initvalue_types()\n\nAdd default value types\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.insertdata-Tuple{DBInterface.Connection, Any, Any, Any}","page":"API","title":"AHRI_TRE.insertdata","text":"insertdata(conn::DBInterface.Connection, table, columns, values)\n\nInsert a set of values into a table, columns list the names of the columns to insert, and values the values to insert\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.insertwithidentity-Tuple{DBInterface.Connection, Any, Any, Any}","page":"API","title":"AHRI_TRE.insertwithidentity","text":"insertwithidentity(conn::DBInterface.Connection, table, columns, values)\n\nInsert a record, returning the identity column value\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.is_ncname-Tuple{AbstractString}","page":"API","title":"AHRI_TRE.is_ncname","text":"is_ncname(s::AbstractString) -> Bool\n\nReturn true if s is a valid NCName (no colon, proper start char, allowed name chars).\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.lines-Tuple{Any}","page":"API","title":"AHRI_TRE.lines","text":"lines(str)\n\nReturns an array of lines in str \n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.list_assets-Tuple{DataStore, Study}","page":"API","title":"AHRI_TRE.list_assets","text":"list_assets(store::DataStore, study::Study; include_versions=true)::Vector{Asset}\n\nReturn a DataFrame containing all assets in the specified study.\n\n'store' is the DataStore object containing the database connection.\n'study' is the Study object to list assets from.\n'include_versions' is a boolean flag indicating whether to include asset versions in the returned Asset objects.\n\nThe DataFrame will contain all columns from the assets table, ordered by name.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.list_assets_df-Tuple{DataStore, Study}","page":"API","title":"AHRI_TRE.list_assets_df","text":"list_assets_df(store::DataStore, study::Study; include_versions=true)::DataFrame\n\nReturn a DataFrame containing all assets in the specified study.\n\n'store' is the DataStore object containing the database connection.\n'study' is the Study object to list assets from.\n'include_versions' is a boolean flag indicating whether to include asset versions in the DataFrame.\n\nIf include_versions is true, the DataFrame will include asset version details\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.list_domainentities-Tuple{DataStore, Int64}","page":"API","title":"AHRI_TRE.list_domainentities","text":"list_domainentities(store::DataStore, domain_id::Int)::DataFrame\n\nReturn a DataFrame containing all entities in the specified domain.\n\n'store' is the DataStore object containing the database connection.\n'domain_id' is the ID of the domain to list entities from.\n\nThe DataFrame will contain all columns from the entities table, ordered by name. This function is useful for retrieving all entities in a domain for further processing or display.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.list_domainrelations-Tuple{DataStore, Int64}","page":"API","title":"AHRI_TRE.list_domainrelations","text":"list_domainrelations(store::DataStore, domain_id::Int)::DataFrame\n\nReturn a DataFrame containing all entity relations in the specified domain.\n\n'store' is the DataStore object containing the database connection.\n'domain_id' is the ID of the domain to list entity relations from.\n\nThe DataFrame will contain all columns from the entityrelations table, ordered by name.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.list_studies-Tuple{DataStore}","page":"API","title":"AHRI_TRE.list_studies","text":"list_studies(store::DataStore)::Vector{Study}\n\nReturn a vector of all Study objects in the specified DataStore.\n\n'store' is the DataStore object containing the database connection.\n\nThis function retrieves all studies from the database, ordered by name.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.lookup_variables-Tuple{Any, Any, Any}","page":"API","title":"AHRI_TRE.lookup_variables","text":"lookup_variables(db, variable_names, domain)\n\nReturns a DataFrame with dataset variable names and ids\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.makeparams-Tuple{Any}","page":"API","title":"AHRI_TRE.makeparams","text":"makeparam(s)\n\nReturn a parameterized string for SQL queries\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.map_value_type-Tuple{AbstractString, Union{Missing, AbstractString}}","page":"API","title":"AHRI_TRE.map_value_type","text":"map_value_type(field_type::String, validation::Union{Missing,String}) -> Int\n\nREDCap fieldtype and validation -> TRE valuetype_id.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.opendatastore","page":"API","title":"AHRI_TRE.opendatastore","text":"opendatastore(server::AbstractString, user::AbstractString, password::AbstractString, database::AbstractString, lake_data::Union{String,Nothing}=nothing, lake_db::Union{String,Nothing}=nothing)\n\nOpen a database connection to a PostgreSQL server with optional DuckDB data lake support. This function connects to a PostgreSQL server using the provided credentials and database name.\n\n\n\n\n\n","category":"function"},{"location":"api/#AHRI_TRE.parse_redcap_choices-Tuple{AbstractString}","page":"API","title":"AHRI_TRE.parse_redcap_choices","text":"parse_redcap_choices(s::AbstractString) -> Vector{NamedTuple{(:value,:code,:description),Tuple{Int,String,Union{String,Missing}}}}\n\nParses \"1, Male | 2, Female\" into a vector of items.\n\nvalue: Int (left id)\ncode:  String (tokenized label; spaces -> _)\ndescription: original label\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.path_to_file_uri-Tuple{AbstractString}","page":"API","title":"AHRI_TRE.path_to_file_uri","text":"path_to_file_uri(path::AbstractString) -> String\n\nConvert a local filesystem path (Windows or Unix) to a file:// URI.\n\nWindows local path:   C:\\Users\\me\\file.txt   -> file:///C:/Users/me/file.txt\nWindows UNC path:     \\srv\\share\\f.txt     -> file://srv/share/f.txt\nUnix path:            /home/me/file.txt         -> file:///home/me/file.txt\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.prepare_datafile-Tuple{AbstractString, String}","page":"API","title":"AHRI_TRE.prepare_datafile","text":"prepare_datafile(file_path::AbstractString, edam_format::String; compress::Bool=false, encrypt::Bool=false) -> DataFile\n\nPrepare a DataFile for registration: validate path, optionally compress, compute digest and populate DataFile fields.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.prepareinsertstatement-Tuple{DBInterface.Connection, Any, Any}","page":"API","title":"AHRI_TRE.prepareinsertstatement","text":"prepareinsertstatement(conn::DBInterface.Connection, table, columns)\n\nPrepare an insert statement for PostgreSQL into table for columns\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.prepareselectstatement-Tuple{DBInterface.Connection, Any, Vector{String}, Vector{String}}","page":"API","title":"AHRI_TRE.prepareselectstatement","text":"prepareselectstatement(conn::DBInterface.Connection, table, columns::Vector{String}, filter::Vector{String})\n\nReturn a statement to select columns from a table, with 0 to n columns to filter on\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.quote_ident-Tuple{AbstractString}","page":"API","title":"AHRI_TRE.quote_ident","text":"quote_ident(name::AbstractString)\n\nReturn a quoted identifier for SQL queries.\n\n'name' is the identifier to quote, typically a table or column name.\n\nThis function wraps the identifier in double quotes and escapes any existing double quotes by doubling them.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.quote_sql_str-Tuple{AbstractString}","page":"API","title":"AHRI_TRE.quote_sql_str","text":"quote_sql_str(s::AbstractString)\n\nReturn a quoted SQL string for use in SQL queries.\n\n's' is the string to quote.\n\nThis function wraps the string in single quotes and escapes any existing single quotes by doubling them.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.read_dataset-Tuple{DataStore, AHRI_TRE.DataSet}","page":"API","title":"AHRI_TRE.read_dataset","text":"read_dataset(store::DataStore, dataset::DataSet)::AbstractDataFrame\n\nRead a dataset from the TRE datastore and return it as an AbstractDataFrame.\n\nstore: The DataStore object containing the datastore connection.\ndataset: The DataSet object representing the dataset to be read.\n\nThis function retrieves the dataset from the datastore and converts it to an AbstractDataFrame.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.read_dataset-Tuple{DataStore, String, String}","page":"API","title":"AHRI_TRE.read_dataset","text":"read_dataset(store::DataStore, study_name::String, dataset_name::String)::AbstractDataFrame\n\nRead a dataset from the TRE datastore by study name and dataset name.\n\nstore: The DataStore object containing the datastore connection.\nstudy_name: The name of the study containing the dataset.\ndataset_name: The name of the dataset to be read.\n\nThis function retrieves the study and dataset asset from the datastore, gets the latest version of the dataset, and converts it to an AbstractDataFrame.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.redcap_export_eav-Tuple{AbstractString, AbstractString}","page":"API","title":"AHRI_TRE.redcap_export_eav","text":"redcap_export_eav(api_url::AbstractString, api_token::AbstractString; forms::Vector{String}=String[], fields::Vector{String}=String[],lake_root = ENV[\"TRE_LAKE_PATH\"], decode::Bool=false)::String\n\nExports REDCap data in EAV format (Entity-Attribute-Value) as a CSV file.\n\napi_url: REDCap API URL\napi_token: API token\nforms: Optional vector of form names to export (default: all forms)\nfields: Optional vector of field names to export (default: all fields)\nlakeroot: Root directory for saving the export file (default: TRELAKE_PATH environment variable)\ndecode: If true, decode the response body from ISO-8859-2 to UTF-8 before saving\n\nReturns the path to the saved CSV file. REDCap Bug: The API ignores the fields parameter and returns all fields, irrespective of the fields parameter.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.redcap_fields-Tuple{AbstractString, AbstractString}","page":"API","title":"AHRI_TRE.redcap_fields","text":"redcap_fields(api_url::AbstractString, api_token::AbstractString;\nforms::Union{Nothing,Vector{String}}=nothing,\ninclude_nondata::Bool=false)::Vector{String}\n\nFetches REDCap metadata fields, optionally filtering by forms and including non-data fields. Returns a vector of field names.\n\nurl: REDCap API URL\ntoken: API token\nforms: Optional vector of form names to filter by (default: all forms)\ninclude_nondata: If true, include non-data fields like descriptive, file, sql, signature\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.redcap_metadata-Tuple{AbstractString, AbstractString}","page":"API","title":"AHRI_TRE.redcap_metadata","text":"redcap_metadata(url::AbstractString, token::AbstractString;\n                forms::Union{Nothing,Vector{String}}=nothing) -> DataFrame\n\nDownloads REDCap data dictionary (metadata) as a DataFrame.\n\nurl: REDCap API URL\ntoken: API token\nforms: Optional vector of form names to filter by (default: all forms)\nfields: Optional vector of field names to filter by (default: all fields)\n\nREDCap Bug: The API ignores the fields parameter and returns all fields, irrespective of the fields parameter. Returns a DataFrame with columns: fieldname, fieldtype, textvalidationtypeorshowslidernumber, selectchoicesorcalculations, fieldlabel, field_note.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.redcap_post-Tuple{Any, AbstractDict}","page":"API","title":"AHRI_TRE.redcap_post","text":"redcap_post(body::Dict)::HTTP.Response\n\nDo a POST request to the REDCap API with the given body.\n\napi_url: REDCap API URL\nbody: Dictionary containing the POST parameters\nretry: Number of retry attempts in case of failure (default: 5)\n\nReturns the HTTP response object.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.redcap_post_tofile-Tuple{Any, AbstractDict, String}","page":"API","title":"AHRI_TRE.redcap_post_tofile","text":"redcap_post_tofile(api_url, body::AbstractDict, outputfile::String; decode::Bool=false, retry=5)::Bool\n\nDo a POST request to the REDCap API with the given body and save the response to a file.\n\napi_url: REDCap API URL\nbody: Dictionary containing the POST parameters\noutputfile: File path to save the response\ndecode: If true, decode the response body from ISO-8859-2 to UTF-8 before saving\nretry: Number of retry attempts in case of failure (default: 5)\n\nReturns true if successful, false otherwise.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.redcap_project_info-Tuple{AbstractString, AbstractString}","page":"API","title":"AHRI_TRE.redcap_project_info","text":"redcap_project_info(url, token; raw=false) -> NamedTuple | JSON3.Object\n\nFetch high-level REDCap project information (title, purpose, status, etc.). When raw=true, return the parsed JSON3.Object directly. When raw=false (default), return a NamedTuple with symbol keys suitable for constructing a DataFrame or logging.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.redcap_project_info_df-Tuple{AbstractString, AbstractString}","page":"API","title":"AHRI_TRE.redcap_project_info_df","text":"redcap_project_info_df(url, token) -> DataFrame\n\nConvenience wrapper returning a single-row DataFrame with project metadata.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.register_datafile-Tuple{DataStore, DataFile}","page":"API","title":"AHRI_TRE.register_datafile","text":"register_datafile(store::DataStore, datafile::DataFile)\n\nRegister a DataFile in the TRE datastore. The assetversion must already exist in the datastore.\n\nstore: The Datastore object containing connection details for the datastore.\ndatafile: The DataFile object to register, which must have a valid assetversion.\n\nThis function will insert the datafile into the database and associate it with the specified asset version.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.register_dataset-Tuple{DataStore, AHRI_TRE.DataSet}","page":"API","title":"AHRI_TRE.register_dataset","text":"register_dataset(store::DataStore, dataset::DataSet)::Nothing\n\nRegister a Dataset in the TRE datastore.\n\nstore: The DataStore object containing connection details for the datastore.\ndataset: The Dataset object to register, which must have a valid dataset_id.\n\nThis function will insert the dataset into the database.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.register_redcap_datadictionary-Tuple{DataStore, Int64, String, String}","page":"API","title":"AHRI_TRE.register_redcap_datadictionary","text":"register_redcap_datadictionary(store::DataStore,\ndomain_id::Int, redcap_url::String, redcap_token::String;\nforms=String[], vocabulary_prefix::String=\"\", use_transaction = true)::DataFrame\n\nField types: \"descriptive\",\"sql\",\"signature\",\"file\" are ignored. This function downloads the REDCap metadata, processes it, and registers variables in the given DataStore.     Database actions are wrapped in a transaction and rolled back on error, if use_transaction = true (default).\n\nstore: DataStore instance to use for database operations\ndomain_id: Domain ID to register variables under\nredcap_url: REDCap API URL\nredcap_token: API token for the REDCap project\nforms: Optional vector of form names to filter by (default: all forms)\nvocabulary_prefix: Optional prefix for vocabulary names (default: empty)\nuse_transaction: If true (default), wrap database actions in a transaction\n\nReturns a DataFrame with columns: fieldname, variableid, valuetypeid, vocabularyid, fieldtype, validation, label, note.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.replace_database-Tuple{DBInterface.Connection, String, String, String}","page":"API","title":"AHRI_TRE.replace_database","text":"replace_database(conn::DBInterface.Connection, database::String, user::String, password::String)\n\nReplace the existing database with a new one, dropping it first if it exists.      This function is used to reset the database, typically for development or testing purposes.     Creates the user role if it does not exist, and set the rolle as the owner of the new database. NB: ONLY USE THIS FUNCTION IN DEVELOPMENT OR TESTING ENVIRONMENTS,     as it will drop the existing database, lake and all its contents.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.save_transformation!-Tuple{DataStore, Transformation}","page":"API","title":"AHRI_TRE.save_transformation!","text":"save_transformation!(store::DataStore, transformation::Transformation)::Transformation\n\nSave a transformation in the TRE datastore.\n\nstore: The DataStore object containing connection details for the datastore.\ntransformation: The Transformation object to save\n\nThis function will insert the transformation into the database and return the updated Transformation object with its transformation_id set.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.savedataframe-Tuple{DBInterface.Connection, DataFrames.AbstractDataFrame, Any}","page":"API","title":"AHRI_TRE.savedataframe","text":"savedataframe(con::DBInterface.Connection, df::AbstractDataFrame, table)\n\nSave a DataFrame to a database table, the names of the dataframe columns should be identical to the table column names in the database\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.savedataframetolake-Tuple{DataStore, DataFrames.AbstractDataFrame, String, String}","page":"API","title":"AHRI_TRE.savedataframetolake","text":"savedataframetolake(lake::DBInterface.Connection, df::AbstractDataFrame, name::String, description::String)\n\nSave dataframe to data lake, convert columns of type Missing to Union{String, Missing} for DuckDB compatibility NOTE: This function assumes that the ducklake metadatabase is attached as LAKE_ALIAS DEPPRECATED: DataFrames should be saved with a valid DataSet object\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.selectdataframe-Tuple{DBInterface.Connection, String, Vector{String}, Vector{String}, Union{Tuple, AbstractDict, NamedTuple, AbstractVector}}","page":"API","title":"AHRI_TRE.selectdataframe","text":"selectdataframe(conn::DBInterface.Connection, table::String, columns::Vector{String}, filter::Vector{String}, filtervalues::DBInterface.StatementParams)::AbstractDataFrame\n\nReturn a dataframe from a table, with 0 to n columns to filter on\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.sha256_digest_hex-Tuple{AbstractString}","page":"API","title":"AHRI_TRE.sha256_digest_hex","text":"sha256_digest_hex(path::AbstractString) -> String\n\nCompute the SHA-256 (SHA2-256) digest of a file and return it as a lowercase hex string.\n\npath: Path to the file to hash.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.to_ncname-Tuple{AbstractString}","page":"API","title":"AHRI_TRE.to_ncname","text":"to_ncname(s::AbstractString; replacement=\"_\", prefix=\"_\", avoid_reserved=true) -> String\n\nConvert s into a valid NCName:\n\nReplaces any invalid char with replacement (default _).\nIf the first char is invalid, prepends prefix (default _).\nRemoves/condenses repeated replacements.\nReplaces : with replacement.\nOptionally avoids names starting with 'xml' (case-insensitive) by prepending prefix.\nIf strict=true, disallows - and . in names (replaces them too).\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.transform_eav_to_dataset-Tuple{DataStore, DataFile}","page":"API","title":"AHRI_TRE.transform_eav_to_dataset","text":"transform_eav_to_dataset(store::DataStore, datafile::DataFile)::DataSet\n\nTransform an EAV (Entity-Attribute-Value) data file into a dataset.\n\n'store' is the DataStore object containing the database connection.\n'datafile' is the DataFile object representing the EAV data file.\n\nThis function creates a new dataset in the database by pivoting the EAV data into a wide format. It aggregates multiple values for the same field per record into a single column. The dataset name is derived from the datafile's asset name, dropping the \"eav\" suffix if present. Returns a DataSet object representing the transformed data. This function assumes the EAV data is stored in a csv table with columns: record, fieldname, and value.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.transform_eav_to_table!-Tuple{DataStore, DataFile, AHRI_TRE.DataSet}","page":"API","title":"AHRI_TRE.transform_eav_to_table!","text":"transform_eav_to_table!(store::DataStore, datafile::DataFile, dataset::DataSet)::Nothing\n\nTransform an EAV (Entity-Attribute-Value) data file into a table in the TRE lake.\n\n'store' is the DataStore object containing the database connection.\n'datafile' is the DataFile object representing the EAV data file.\n'dataset' is the DataSet object representing the target dataset.\n\nThis function creates a new table in the TRE lake by pivoting the EAV data into a wide format. It aggregates multiple values for the same field per record into a single column. The table name is derived from the dataset's asset name. This function assumes the EAV data is stored in a csv table with columns: record, field_name, and value.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.updatevalues-Tuple{DBInterface.Connection, Vararg{Any, 5}}","page":"API","title":"AHRI_TRE.updatevalues","text":"updatevalues(conn::DBInterface.Connection, table, condition_column, condition_value, columns, values)\n\nUpdate value of column given conditionvalue in conditioncolumn\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.updatevariable_vocabulary-Tuple{DBInterface.Connection, Any, Any, Any}","page":"API","title":"AHRI_TRE.updatevariable_vocabulary","text":"updatevariable_vocabulary(conn::DBInterface.Connection, name, domain_id, vocabulary_id)\n\nUpdate variable vocabulary\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.upsert_domain!-Tuple{Domain, DataStore}","page":"API","title":"AHRI_TRE.upsert_domain!","text":"upsert_domain!(domain::Domain, store::DataStore)::Domain\n\nCreate or update a domain record. If a domain with the same (name, uri) already exists (treating NULL uri correctly), it updates and returns its domainid. Otherwise, it inserts a new row and returns the new domainid.\n\n'domain' is a Domain object containing the name, uri, and description.\n'store' is the DataStore object containing the database connection.\n\nIf the domain has a non-NULL URI, it must be unique with respect to the name and URI combination. If the domain has a NULL URI, it must be unique with respect to the name only, allowing at most one row with a NULL URI for each name. This function returns the updated or newly created Domain object with the domain_id set.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.upsert_entity!-Tuple{Entity, DataStore}","page":"API","title":"AHRI_TRE.upsert_entity!","text":"upsert_entity!(store::DataStore, entity::Entity)::Entity\n\nCreate or update an entity record. If an entity with the same (domainid, name) already exists, it updates and returns its entityid.\n\n'entity' is an Entity object containing the domainid, name, description, ontologynamespace, and ontology_class.\n'store' is the DataStore object containing the database connection.\n\nIf the entity has a non-NULL ontologynamespace and ontologyclass, it must be unique with respect to the (domainid, name) combination. If the entity has a NULL ontologynamespace or ontologyclass, it must be unique with respect to the (domainid, name) combination,  allowing at most one row with a NULL ontologynamespace or ontologyclass for each (domain_id, name).  \n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.upsert_entityrelation!-Tuple{EntityRelation, DataStore}","page":"API","title":"AHRI_TRE.upsert_entityrelation!","text":"upsert_entityrelation!(store::DataStore, r::EntityRelation)::EntityRelation\n\nCreate or update an entity relation record. If a relation with the same (domainid, name) already exists, it updates and returns its entityrelationid.\n\n'r' is an EntityRelation object containing the entityid1, entityid2, domainid, name, description, ontologynamespace, and ontology_class.\n'store' is the DataStore object containing the database connection.\n\nIf the relation has a non-NULL ontologynamespace and ontologyclass, it must be unique with respect to the (domainid, name) combination. If the relation has a NULL ontologynamespace or ontologyclass, it must be unique with respect to the (domainid, name) combination, allowing at most one row with a NULL ontologynamespace or ontologyclass for each (domainid, name). This function returns the updated or newly created EntityRelation object with the entityrelationid and uuid set.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.upsert_study!-Tuple{Study, DataStore}","page":"API","title":"AHRI_TRE.upsert_study!","text":"upsert_study!(study::Study, store::DataStore)::Study\n\nCreate or update a study record. If a study with the same name already exists, it updates and returns the study. Otherwise, it inserts a new row and returns the new study. If study.study_id is nothing, it inserts a new study and lets PostgreSQL assign\n\n'study' is a Study object containing the name, description, externalid, and studytype_id.\n'store' is the DataStore object containing the database connection.\n\nIf the study name is required and it must be unique.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.upsert_variable!-Tuple{Any, Int64, String}","page":"API","title":"AHRI_TRE.upsert_variable!","text":"upsert_variable!(db, domain_id::Int, name::String; value_type_id::Int, vocabulary_id::Union{Nothing,Int}=nothing, description::Union{Missing,String}=missing) -> Int\n\nUpserts into variables on (domainid, name). Returns variableid.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.verify_sha256_digest-Tuple{AbstractString, AbstractString}","page":"API","title":"AHRI_TRE.verify_sha256_digest","text":"verify_sha256_digest(path::AbstractString, expected_hex::AbstractString) -> Bool\n\nCheck whether the file's SHA-256 digest matches the expected hex string. Returns true on match, false otherwise.\n\n\n\n\n\n","category":"method"},{"location":"introduction/#Introduction","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"This package creates and ingest data for the AHRI Trusted Research Environment into a PostgreSQL and ducklake managed data lake.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Data ingestion is specific to a study, where a study is any research study collecting data about entities and the relationships between these entities.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"AHRI_TRE can import data directly from a REDCap project and create the necessary metadata to describe the data in the project.","category":"page"},{"location":"introduction/#Database-Structure","page":"Introduction","title":"Database Structure","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"The conceptual model of the AHRI_TRE is shown in Figure 1. (Image: Fig 1: AHRI-TRE Conceptual Model)","category":"page"},{"location":"introduction/#Studies","page":"Introduction","title":"Studies","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"A study is described in the following tables:","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Table Name Description\nstudies A research study collecting data about entities and the relationships between them\nstudy_types Record different types of studies contributing data to the TRE\nstudy_access Access control linking users to studies and used in row level security\nstudy_domains Associate studies with domains","category":"page"},{"location":"introduction/#Entities","page":"Introduction","title":"Entities","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"The entities and the relationships between them are described in the following tables:","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Table Name Description\nentities Entities such as individuals, households, etc. and links to public ontologies\nentityrelations Relationships between entities, such as household membership, and links to public<br>ontologies\nentity_instances Specific instances of entities in a study, allows linking of instances,<br>e.g. a person to data assets containing data about that person\nrelation_instances Instances of entity relationships, e.g. the membership of a specific person to<br>an instance of a household","category":"page"},{"location":"introduction/#Assets","page":"Introduction","title":"Assets","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"The data assets containing the data collected by a study are described in the following tables:","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Table Name Description\nassets Digital assets such as datasets and files contained in the data lake\ndataassetentities Link assets to entity instances, to track instances associated with an asset\nasset_versions Used to track different versions of assets\ndatafiles A specific version of a file (binary large object(BLOB)) stored in the data lake\ndataset An asset version of tabular dataset managed by ducklake in the data lake\ndataset_variables The variables associated with the columns in the dataset","category":"page"},{"location":"introduction/#Transformations","page":"Introduction","title":"Transformations","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Transformations tracks the process of ingesting, transforming and exporting data from the TRE. This is described in the following tables:","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Table Name Description\ntransformations Documents the transformation (ingest, transform, entity instance generation,<br>exporting, and placement in a data repository)\ntransformation_inputs The input data asset/s used by the transformation\ntransformation_outputs The data asset/s produced by the transformation","category":"page"},{"location":"introduction/#Variables","page":"Introduction","title":"Variables","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"The variables representing the data contained in datasets, is described by the following tables:","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Table Name Description\ndomains Variable names are unique within a domain\nvariables Documents a variable\nvalue_types Representing the different datatypes, variables can assume\nvocabularies The values a categorical variables can assume, are contained in a vocabulary\nvocabulary_items The individual categories (codes) in a vocabulary\nvocabulary_mapping The items of one vocabulary can be mapped to those in another vocabulary","category":"page"},{"location":"#AHRI_TRE.jl","page":"Home","title":"AHRI_TRE.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for AHRI_TRE.jl","category":"page"}]
}
