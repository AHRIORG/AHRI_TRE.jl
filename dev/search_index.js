var documenterSearchIndex = {"docs":
[{"location":"api/#Functions","page":"API","title":"Functions","text":"","category":"section"},{"location":"api/#Function-Specifications","page":"API","title":"Function Specifications","text":"","category":"section"},{"location":"api/#Public-API-Types","page":"API","title":"Public API - Types","text":"","category":"section"},{"location":"api/#Public-API-Constants","page":"API","title":"Public API - Constants","text":"","category":"section"},{"location":"api/#Public-API-functions","page":"API","title":"Public API - functions","text":"","category":"section"},{"location":"api/#Private-Types-and-Constants","page":"API","title":"Private Types & Constants","text":"","category":"section"},{"location":"api/#Private-functions","page":"API","title":"Private functions","text":"","category":"section"},{"location":"api/#AHRI_TRE.DatabaseFlavour","page":"API","title":"AHRI_TRE.DatabaseFlavour","text":"Abstract type for database flavors to enable multiple dispatch.\n\n\n\n\n\n","category":"type"},{"location":"api/#AHRI_TRE.add_domain!-Tuple{DataStore, Domain}","page":"API","title":"AHRI_TRE.add_domain!","text":"add_domain!(store::DataStore, domain::Domain)::Domain\n\nAdd a new domain record. If a domain with the same (name, uri) already exists (treating NULL uri correctly), it raises an error.\n\n'domain' is a Domain object containing the name, uri, and description.\n'store' is the DataStore object containing the database connection.\n\nIf the domain has a non-NULL URI, it must be unique with respect to the name and URI combination. If the domain has a NULL URI, it must be unique with respect to the name only, allowing at most one row with a NULL URI for each name. This function returns the newly created Domain object with the domain_id set.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.add_study!-Tuple{DataStore, Study, Domain}","page":"API","title":"AHRI_TRE.add_study!","text":"add_study!(store::DataStore, study::Study, domain::Domain)::Study\n\nCreate a new study in the TRE datastore and associate it with a domain.\n\nstore: The DataStore object containing the datastore connection.\nstudy: The Study object representing the study to be created.\ndomain: The Domain object representing the domain to associate with the study.\n\nThis function inserts or updates the study in the datastore and links it to the specified domain.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.add_study_domain!-Tuple{DataStore, Study, Domain}","page":"API","title":"AHRI_TRE.add_study_domain!","text":"add_study_domain!(store::DataStore, study::Study, domain::Domain)\n\nAdd a domain to a study by inserting a record into the study_domains table.\n\n'store' is the DataStore object containing the database connection.\n'study' is the Study object containing the study_id.\n'domain' is the Domain object containing the domain_id.\n\nIf the combination of (studyid, domainid) already exists, it does nothing. If the domain is not already in the study.domains list, it adds it to the study.domains vector.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.add_transformation!-Tuple{DataStore, Transformation}","page":"API","title":"AHRI_TRE.add_transformation!","text":"add_transformation!(store::DataStore, transformation::Transformation)::Transformation\n\nSave a transformation in the TRE datastore.\n\nstore: The DataStore object containing connection details for the datastore.\ntransformation: The Transformation object to save\n\nThis function will insert the transformation into the database and return the updated Transformation object with its transformation_id set.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.add_transformation_input-Tuple{DataStore, Int64, Base.UUID}","page":"API","title":"AHRI_TRE.add_transformation_input","text":"add_transformation_input(store::DataStore, transformation_id::Int, version_id::UUID)::Nothing\n\nAdd a transformation input to the transformation_inputs table.\n\nstore: The DataStore object containing connection details for the datastore.\ntransformation_id: The ID of the transformation to which the input belongs.\nversion_id: The UUID of the asset version that is the input to the transformation.\n\nThis function will insert a new record into the transformation_inputs table linking the transformation to the asset version.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.add_transformation_input-Tuple{DataStore, Transformation, AssetVersion}","page":"API","title":"AHRI_TRE.add_transformation_input","text":"add_transformation_input(store::DataStore, transformation::Transformation, version::AssetVersion)::Nothing\n\nAdd a transformation input to the transformation_inputs table using Transformation and AssetVersion objects.\n\nstore: The DataStore object containing connection details for the datastore.\ntransformation: The Transformation object containing the transformation_id.\nversion: The AssetVersion object containing the version_id.\n\nThis function checks that both the transformation and version have valid IDs before calling the lower-level function.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.add_transformation_output-Tuple{DataStore, Int64, Base.UUID}","page":"API","title":"AHRI_TRE.add_transformation_output","text":"add_transformation_output(store::DataStore, transformation_id::Int, version_id::UUID)::Nothing\n\nAdd a transformation output to the transformation_outputs table.\n\nstore: The DataStore object containing connection details for the datastore.\ntransformation_id: The ID of the transformation to which the output belongs.\nversion_id: The UUID of the asset version that is the output of the transformation.\n\nThis function will insert a new record into the transformation_outputs table linking the transformation to the asset version.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.add_transformation_output-Tuple{DataStore, Transformation, AssetVersion}","page":"API","title":"AHRI_TRE.add_transformation_output","text":"add_transformation_output(store::DataStore, transformation::Transformation, version::AssetVersion)::Nothing\n\nAdd a transformation output to the transformation_outputs table using Transformation and AssetVersion objects.\n\nstore: The DataStore object containing connection details for the datastore.\ntransformation: The Transformation object containing the transformation_id.\nversion: The AssetVersion object containing the version_id.\n\nThis function checks that both the transformation and version have valid IDs before calling the lower-level function.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.add_variable!-Tuple{DataStore, AHRI_TRE.Variable}","page":"API","title":"AHRI_TRE.add_variable!","text":"add_variable!(datastore::DataStore, variable::Variable)::Variable\n\nAdd a Variable to the TRE datastore, upserting if it already exists.\n\n'datastore' is the DataStore object containing the database connection.\n'variable' is the Variable object to add.\n\nThis function will upsert the variable into the database and set its variable_id.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.attach_datafile-Tuple{DataStore, AssetVersion, AbstractString, String}","page":"API","title":"AHRI_TRE.attach_datafile","text":"attach_datafile(store::DataStore, assetversion::AssetVersion, file_path::AbstractString, edam_format::String;\ncompress::Bool=false, encrypt::Bool=false)::DataFile\n\nAttach a data file to an existing asset version in the TRE datastore.\n\nstore: The DataStore object containing connection details for the datastore.\nassetversion: The AssetVersion object to which the data file will be attached.\nfile_path: The full path including the file name to the file.\nedam_format: The EDAM format of the data file (e.g., \"http://edamontology.org/format_3752\" for a csv file).\ncompress: Whether the file should be compressed (default is false).   If true, the file will be compressed using zstd, and the existing file will be replaced with the compressed version.\nencrypt: Whether the file should be encrypted (default is false). NOT currently implemented\n\nThis function does not copy the file, it only registers it in the TRE datastore. It assumes the file is already in the data lake and creates a DataFile object associated with the given asset version.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.attach_datafile-Tuple{DataStore, Study, String, AbstractString, String}","page":"API","title":"AHRI_TRE.attach_datafile","text":"attach_datafile(store::DataStore, study::Study, asset_name::String,\nfile_path::AbstractString, edam_format::String; description::Union{String,Missing}=missing, compress::Bool=false, encrypt::Bool=false)::DataFile\n\nAttach a data file that is already in the data lake to the TRE datastore.\n\nstore: The DataStore object containing connection details for the datastore.\nstudy: The Study object to associate with the data file.\nasset_name: The name of the asset to which the data file will be attached. Must comply with xsd:NCName restrictions.\nfile_path: The full path including the file name to the file.\nedam_format: The EDAM format of the data file (e.g., \"http://edamontology.org/format_3752\" for a csv file).\ndescription: A description of the data file (default is missing).\ncompress: Whether the file should be compressed (default is false).   If true, the file will be compressed using zstd, and the existing file will be replaced with the compressed version.\nencrypt: Whether the file should be encrypted (default is false). NOT currently implemented\n\nThis function does not copy the file, it only registers it in the TRE datastore. It assumes the file is already in the data lake and creates an Asset object with a base version\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.attach_datafile_version-Tuple{DataStore, AssetVersion, String, AbstractString, String, Bool, Bool}","page":"API","title":"AHRI_TRE.attach_datafile_version","text":"attach_datafile_version(store::DataStore, assetversion::AssetVersion, version_note::String,\nfile_path::AbstractString, edam_format::String, bumpmajor::Bool, bumpminor::Bool;\ncompress::Bool=false, encrypt::Bool=false)::DataFile\n\nAttach a new data file as a new version to an existing asset in the TRE datastore.\n\nstore: The DataStore object containing connection details for the datastore.\nassetversion: The existing AssetVersion object to which the new data file version will be attached.\nversion_note: A note describing the changes in this new version.\nfile_path: The full path including the file name to the new file.\nedam_format: The EDAM format of the new data file (e.g., \"http://edamontology.org/format_3752\" for a csv file).\nbumpmajor: If true, increments the major version number and resets minor and patch to 0.\nbumpminor: If true, increments the minor version number and resets patch to 0.\ncompress: Whether the file should be compressed (default is false).   If true, the file will be compressed using zstd, and the existing file will be replaced with the compressed version.\nencrypt: Whether the file should be encrypted (default is false). NOT currently implemented\n\nThis function does not copy the file, it only registers it in the TRE datastore. It assumes the file is already in the data lake and creates a new DataFile object associated with a new version of the given asset.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.closedatastore-Tuple{DataStore}","page":"API","title":"AHRI_TRE.closedatastore","text":"closedatastore(store::DataStore)\n\nClose the connections in a DataStore object\n\nstore: A DataStore object with open connections\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.connect_mssql-NTuple{4, AbstractString}","page":"API","title":"AHRI_TRE.connect_mssql","text":"connect_mssql(server::AbstractString, database::AbstractString,\n              user::AbstractString, password::AbstractString;\n              driver::AbstractString=\"ODBC Driver 18 for SQL Server\",\n              encrypt::Bool=true, trust_server_cert::Bool=true) -> Union{ODBC.Connection,Nothing}\n\nCreate a connection to a Microsoft SQL Server database using ODBC.\n\nArguments\n\nserver: The server hostname or IP address (e.g., \"myserver.database.windows.net\")\ndatabase: The database name to connect to\nuser: The username for authentication\npassword: The password for authentication\ndriver: ODBC driver name (default: \"ODBC Driver 18 for SQL Server\")\nencrypt: Whether to use encrypted connection (default: true)\ntrust_server_cert: Whether to trust the server certificate (default: true)\n\nReturns\n\nAn ODBC.Connection object, or nothing if connection fails.\n\nNote\n\nThis function automatically registers the MSSQL ODBC driver with ODBC.jl if not already registered, searching common system installation paths.\n\nExample\n\nconn = connect_mssql(\"myserver.database.windows.net\", \"mydb\", \"user\", \"password\")\ntry\n    result = DBInterface.execute(conn, \"SELECT @@VERSION\") |> DataFrame\n    println(result)\nfinally\n    DBInterface.close!(conn)\nend\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.create_asset","page":"API","title":"AHRI_TRE.create_asset","text":"create_asset(store::DataStore, study::Study, name::String, type::String, description::Union{Missing,String}=missing)::Asset\n\nCreate a new asset in the TRE datastore and the base version of the asset.\n\nstore: The DataStore object containing connection details for the datastore.\nstudy: The Study object to associate with the asset.\nname: The name of the asset. Will be coherced to xsd:NCName format.\ntype: The type of the asset, either \"dataset\" or \"file\".\ndescription: An optional description of the asset (default is missing).\n\nReturns the created Asset object with its asset_id and the first version.\n\n\n\n\n\n","category":"function"},{"location":"api/#AHRI_TRE.create_entity!-Tuple{DataStore, Entity, Domain}","page":"API","title":"AHRI_TRE.create_entity!","text":"create_entity!(store::DataStore, entity::Entity, domain::Domain)::Entity\n\nCreate a new entity in the TRE datastore and associate it with a domain.\n\nstore: The DataStore object containing the datastore connection.\nentity: The Entity object representing the entity to be created.\ndomain: The Domain object representing the domain to associate with the entity.\n\nThis function inserts or updates the entity in the datastore and links it to the specified domain.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.create_entity_relation!","page":"API","title":"AHRI_TRE.create_entity_relation!","text":"create_entity_relation!(store::DataStore, subject_name::String, object_name::String, relation_name::String, \n                             domain_name::String, description::Union{Missing,String} = missing)::EntityRelation\n\nCreate a new entity relation in the TRE datastore by specifying subject and object entity names, relation name, and domain name.\n\nstore: The DataStore object containing the datastore connection.\nsubject_name: The name of the subject entity in the relation.\nobject_name: The name of the object entity in the relation.\nrelation_name: The name of the relation.\ndomain_name: The name of the domain to associate with the entity relation.\ndescription: An optional description of the entity relation (default is missing).\n\nThis function looks up the subject and object entities by name within the specified domain, creates the entity relation, and inserts or updates it in the datastore.\n\n\n\n\n\n","category":"function"},{"location":"api/#AHRI_TRE.create_entity_relation!-Tuple{DataStore, EntityRelation, Domain}","page":"API","title":"AHRI_TRE.create_entity_relation!","text":"create_entity_relation!(store::DataStore, entityrelation::EntityRelation, domain::Domain)::EntityRelation\n\nCreate a new entity relation in the TRE datastore and associate it with a domain.\n\nstore: The DataStore object containing the datastore connection.\nentityrelation: The EntityRelation object representing the entity relation to be created.\ndomain: The Domain object representing the domain to associate with the entity relation.\n\nThis function inserts or updates the entity relation in the datastore and links it to the specified domain.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.create_transformation-Tuple{String, String}","page":"API","title":"AHRI_TRE.create_transformation","text":"create_transformation(transformation_type::String, description::String;\n    repository_url::Union{Missing,String}=missing,\n    commit_hash::Union{Missing,String}=missing,\n    file_path::Union{Missing,String}=missing)::Transformation\n\nCreate a Transformation object.\n\ntransformation_type: The type of transformation, must be one of \"ingest\", \"transform\", \"entity\", or \"export\".\ndescription: A description of the transformation.\nrepository_url: An optional URL of the repository containing the transformation code (default is missing\ncommit_hash: An optional commit hash of the transformation code (default is missing).\nfile_path: An optional file path within the repository for the transformation code (default is missing).\n\nThis function returns a Transformation object with the specified properties.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.createdatastore-Tuple{DataStore}","page":"API","title":"AHRI_TRE.createdatastore","text":"createdatastore(store::DataStore; superuser::String=\"postgres\", superpwd::String=\"\", port::Int=5432)\n\nCreate or replace a PostgreSQL database for the TRE datastore, including the datalake if specified. This function creates a PostgreSQL database with the specified name and user credentials, and optionally creates a data lake using the DuckDb extension ducklake.     store::DataStore: The DataStore object containing connection details for the datastore and datalake databases.     superuser::String: The superuser name for PostgreSQL (default is \"postgres\").     superpwd::String: The superuser password for PostgreSQL (default is empty).     port::Int: The port number for the PostgreSQL server (default is 5432 NB: ONLY USE THIS FUNCTION IN DEVELOPMENT OR TESTING ENVIRONMENTS,     as it will drop the existing database, lake and all its contents.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.dataset_to_arrow-Tuple{DataStore, DataSet, String}","page":"API","title":"AHRI_TRE.dataset_to_arrow","text":"dataset_to_arrow(db, dataset, datapath)\n\nSave a dataset in the arrow format\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.dataset_to_csv-Tuple{DataStore, DataSet, String}","page":"API","title":"AHRI_TRE.dataset_to_csv","text":"dataset_to_csv(store::DataStore, dataset::DataSet, outputdir::String; replace::Bool=false, compress=false)\n\nSave a dataset in compressed csv format\n\nstore: The DataStore object containing the datastore and datalake connections.\ndataset: The DataSet object to be saved as CSV.\noutputdir: The directory where the CSV file will be saved.\nreplace: If true, will overwrite existing files (default is false).\ncompress: If true, will save the CSV file in compressed .zst format (default is false).\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.dataset_to_dataframe-Tuple{DataStore, DataSet}","page":"API","title":"AHRI_TRE.dataset_to_dataframe","text":"dataset_to_dataframe(store::DataStore, dataset::DataSet)::DataFrame\n\nRetrieve a dataset from store.lake and return as a DataFrame\n\nstore: The DataStore object containing the datastore and datalake connections.\ndataset: The DataSet object to be retrieved. NB version must be set.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.dataset_variables-Tuple{DBInterface.Connection, DataSet}","page":"API","title":"AHRI_TRE.dataset_variables","text":"dataset_variables(db::DBInterface.Connection, dataset)::AbstractDataFrame\n\nReturn the list of variables in a dataset\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_asset-Tuple{DataStore, Base.UUID}","page":"API","title":"AHRI_TRE.get_asset","text":"get_asset(store::DataStore, asset_id::UUID)::Union{Asset,Nothing}\n\nReturn an Asset object by its asset_id in the specified DataStore.\n\n'store' is the DataStore object containing the database connection.\n'asset_id' is the UUID of the asset to search for.\n\nIf no asset is found, it returns nothing. If an asset is found, it returns an Asset object with its versions populated.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_asset-Tuple{DataStore, Study, String}","page":"API","title":"AHRI_TRE.get_asset","text":"get_asset(store::DataStore, study::Study, name::String)::Union{Asset,Nothing}\n\nReturn an Asset object by its name in the specified study.\n- 'store' is the DataStore object containing the database connection.\n- 'study' is the Study object to search in.\n- 'name' is the name of the asset to search for.\nIf no asset is found, it returns `nothing`.\nIf an asset is found, it returns an Asset object\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_datafile_metadata-Tuple{DataStore, DataFile}","page":"API","title":"AHRI_TRE.get_datafile_metadata","text":"get_datafile_metadata(store::DataStore, datafile::DataFile)::Datafile\n\nRetrieve the metadata of a data file from the datastore.\n\nstore: The DataStore object containing the database connection.\ndatafile: The DataFile object for which to retrieve metadata. It must have a persisted version with a version_id.\n\nThis function returns a DataFile object containing the metadata of the specified data file.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_dataset-Tuple{DataStore, String, String}","page":"API","title":"AHRI_TRE.get_dataset","text":"get_dataset(store::DataStore, study_name::String, dataset_name::String)::Union{DataSet,Nothing}\n\nRetrieve a dataset object from the TRE datastore by study name and dataset name.\n\nstore: The DataStore object containing the datastore connection.\nstudy_name: The name of the study containing the dataset.\ndataset_name: The name of the dataset to be retrieved.\n\nThis function retrieves the study and dataset asset from the datastore, gets the latest version of the dataset, and returns a DataSet object. Use read_dataset to read the actual dataset contents.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_dataset_variables-Tuple{DataStore, DataSet}","page":"API","title":"AHRI_TRE.get_dataset_variables","text":"get_dataset_variables(store::DataStore, dataset::DataSet)::Vector{Variable}\n\nRetrieve the variables associated with a dataset from the datastore.\n\nstore: The DataStore object containing the database connection.\ndataset: The DataSet object for which to retrieve variables.\n\nThis function returns a vector of Variable objects associated with the specified dataset. If the dataset already has variables populated, it returns those directly.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_dataset_versions-Tuple{DataStore, String, String}","page":"API","title":"AHRI_TRE.get_dataset_versions","text":"get_dataset_versions(store::DataStore, study_name::String, dataset_name::String)::Vector{DataSet}\n\nRetrieve all versions of a dataset from the TRE datastore by study name and dataset name.\n\nstore: The DataStore object containing the datastore connection.\nstudy_name: The name of the study containing the dataset.\ndataset_name: The name of the dataset to be retrieved.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_datasetname-Tuple{DataSet}","page":"API","title":"AHRI_TRE.get_datasetname","text":"get_datasetname(dataset::DataSet; include_schema::Bool=false)::String\n\nReturn a valid dataset name for the dataset, optionally including the schema (study) name.\n\ndataset: The DataSet object for which to generate the name.\ninclude_schema: If true, includes the schema (study) name as a prefix to the dataset name (default is false).\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_domain-Tuple{DataStore, AbstractString}","page":"API","title":"AHRI_TRE.get_domain","text":"get_domain(store::DataStore, name::AbstractString; uri::Union{Nothing,String}=nothing)::Union{Domain,Nothing}\n\nReturn a Domain object by its name (and optional URI) in the specified DataStore. If uri is nothing, it searches for the domain by name only. If uri is provided, it searches for the domain by both name and URI. If no domain is found, it returns nothing. If a domain is found, it returns a Domain object with the domain_id, name, uri, and description.\n\n'store' is the DataStore object containing the database connection.\n'name' is the name of the domain to search for.\n'uri' is an optional URI to further filter the domain search.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_domain_variables-Tuple{Any, Domain}","page":"API","title":"AHRI_TRE.get_domain_variables","text":"get_domain_variables(store, domain::Domain)::Vector{Variable}\n\nReturn a vector of Variable objects associated with the specified domain.\n\n'store' is the DataStore object containing the database connection.\n'domain' is the Domain object containing the domain_id.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_domainentities-Tuple{DataStore, Domain}","page":"API","title":"AHRI_TRE.get_domainentities","text":"get_domainentities(store::DataStore, domain::Domain)::Vector{Entity}\n\nReturn a vector of Entity objects in the specified domain.\n\n'store' is the DataStore object containing the database connection.\n'domain' is the Domain object containing the domain_id.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_domainentities-Tuple{DataStore, Int64}","page":"API","title":"AHRI_TRE.get_domainentities","text":"get_domainentities(store::DataStore, domain_id::Int)::Vector{Entity}\n\nReturn a vector of Entity objects in the specified domain.\n\n'store' is the DataStore object containing the database connection.\n'domain_id' is the ID of the domain to list entities from.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_domainrelations-Tuple{DataStore, Domain}","page":"API","title":"AHRI_TRE.get_domainrelations","text":"get_domainrelations(store::DataStore, domain::Domain)::Vector{EntityRelation}\n\nReturn a vector of EntityRelation objects in the specified domain.\n\n'store' is the DataStore object containing the database connection.\n'domain' is the Domain object containing the domain_id.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_domainrelations-Tuple{DataStore, Int64}","page":"API","title":"AHRI_TRE.get_domainrelations","text":"get_domainrelations(store::DataStore, domain_id::Int)::Vector{EntityRelation}\n\nReturn a vector of EntityRelation objects in the specified domain.\n\n'store' is the DataStore object containing the database connection.\n'domain_id' is the ID of the domain to list entity relations from.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_domains-Tuple{DataStore}","page":"API","title":"AHRI_TRE.get_domains","text":"get_domains(store::DataStore)::Vector{Domain}\n\nReturn a vector of all Domain objects in the specified DataStore.\n\n'store' is the DataStore object containing the database connection.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_entity-Tuple{DataStore, Int64, String}","page":"API","title":"AHRI_TRE.get_entity","text":"get_entity(store::DataStore, domain_id::Int, name::String)::Union{Entity,Nothing}\n\nReturn an Entity object by its name in the specified domain.\n\n'store' is the DataStore object containing the database connection.\n'domain_id' is the ID of the domain to search in.\n'name' is the name of the entity to search for.\n\nIf no entity is found, it returns nothing.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_entityrelation-Tuple{DataStore, Int64, String}","page":"API","title":"AHRI_TRE.get_entityrelation","text":"get_entityrelation(store::DataStore, domain_id::Int, name::String)::Union{EntityRelation,Nothing}\n\nReturn an EntityRelation object by its name in the specified domain.\n\n'store' is the DataStore object containing the database connection.\n'domain_id' is the ID of the domain to search in.\n'name' is the name of the entity relation to search for.\n\nIf no entity relation is found, it returns nothing. If an entity relation is found, it returns an EntityRelation object\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_studies-Tuple{DataStore}","page":"API","title":"AHRI_TRE.get_studies","text":"get_studies(store::DataStore)::Vector{Study}\n\nReturn a vector of all Study objects in the specified DataStore.\n\n'store' is the DataStore object containing the database connection.\n\nThis function retrieves all studies from the database, ordered by name.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_study-Tuple{DataStore, AbstractString}","page":"API","title":"AHRI_TRE.get_study","text":"get_study(store::DataStore, name::AbstractString)::Union{Study,Nothing}\n\nReturn a Study object by its name in the specified DataStore.\n\n'store' is the DataStore object containing the database connection.\n'name' is the name of the study to search for.\n\nIf no study is found, it returns nothing. If a study is found, it returns a Study object\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_study-Tuple{DataStore, Base.UUID}","page":"API","title":"AHRI_TRE.get_study","text":"get_study(store::DataStore, id::UUID)::Union{Study,Nothing}\n\nReturn a Study object by its UUID in the specified DataStore.\n\nstore is the DataStore object containing the database connection.\nid is the UUID of the study to search for.\n\nIf no study is found, it returns nothing.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_study_assets-Tuple{DataStore, Study}","page":"API","title":"AHRI_TRE.get_study_assets","text":"get_study_assets(store::DataStore, study::Study; include_versions=true)::Vector{Asset}\n\nReturn a DataFrame containing all assets in the specified study.\n\n'store' is the DataStore object containing the database connection.\n'study' is the Study object to list assets from.\n'include_versions' is a boolean flag indicating whether to include asset versions in the returned Asset objects.\n\nThe DataFrame will contain all columns from the assets table, ordered by name.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_study_datafiles-Tuple{DataStore, Study}","page":"API","title":"AHRI_TRE.get_study_datafiles","text":"get_study_datafiles(store::DataStore, study::Study)::Vector{DataFile}\n\nRetrieve all data files associated with a study from the datastore.\n\nstore: The DataStore object containing the database connection.\nstudy: The Study object for which to retrieve data files.\n\nThis function returns a vector of DataFile objects associated with the specified study.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_study_datasets-Tuple{DataStore, Study}","page":"API","title":"AHRI_TRE.get_study_datasets","text":"get_study_datasets(store::DataStore, study::Study; include_versions=false)::Vector{DataSet}\n\nRetrieve all datasets associated with a study from the datastore.\n\nstore: The DataStore object containing the database connection.\nstudy: The Study object for which to retrieve datasets.\ninclude_versions: A boolean flag indicating whether to include all versions of each dataset asset, or just the latest version (default is false).\n\nThis function returns a vector of DataSet objects associated with the specified study.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_study_domains-Tuple{DataStore, Study}","page":"API","title":"AHRI_TRE.get_study_domains","text":"get_study_domains(store::DataStore, study::Study)::Vector{Domain}\n\nReturn a vector of Domain objects associated with the specified Study in the DataStore.\n\n'store' is the DataStore object containing the database connection.\n'study' is the Study object containing the study_id.\n\nThis function retrieves all domains linked to the given study from the study_domains table.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_study_variables-Tuple{DataStore, Study}","page":"API","title":"AHRI_TRE.get_study_variables","text":"get_study_variables(store::DataStore, study::Study, domain::Union{Domain,Nothing}=nothing)::Vector{Variable}\n\nReturn a vector of Variable objects associated with the specified study.\n\n'store' is the DataStore object containing the database connection.\n'study' is the Study object to list variables from.\n'domain' is an optional Domain object to filter variables by domain.\n\nIf domain is provided, only variables from that domain are returned.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_variable-Tuple{DataStore, Int64}","page":"API","title":"AHRI_TRE.get_variable","text":"get_variable(db::DBInterface.Connection, variable_id::Int)\n\nReturns the entry of variable with variable_id\n\nstore: The DataStore object containing the datastore connection.\nvariable_id: The integer ID of the variable to retrieve.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.ingest_file-Tuple{DataStore, Study, String, AbstractString, String}","page":"API","title":"AHRI_TRE.ingest_file","text":"ingest_file(store::DataStore, study::Study, asset_name::String, file_path::AbstractString, edam_format::String;\ndescription::Union{String,Missing}=missing, compress::Bool=false, encrypt::Bool=false, new_version::Bool=false, bumpmajor::Bool = false, bumpminor::Bool=false)::Union{DataFile,Nothing}\n\nIngest a file into the TRE data lake and register it in the TRE datastore.\n\nstore: The DataStore object containing connection details for the datastore and data lake.\nstudy: The Study object to associate with the ingested file.\nasset_name: The name of the asset to which the file will be attached. Must comply with xsd:NCName restrictions.\nfile_path: The full path including the file name to the file to be ingested.\nedam_format: The EDAM format of the file (e.g., \"http://edamontology.org/format_3752\" for a csv file).\ndescription: A description of the data file (default is missing).\ncompress: Whether the file should be compressed (default is false).   If true, the file will be compressed using zstd before being copied to the data lake.\nencrypt: Whether the file should be encrypted (default is false). NOT currently implemented\nnew_version: If true, and an asset with the same name already exists in the study, a new version will be created (default is false).\nbumpmajor: If true, increments the major version number and resets minor and patch to 0 for the new version (default is false).\nbumpminor: If true, increments the minor version number and resets patch to 0 for the new version (default is false).\n\nThis function copies the file to the data lake directory, optionally compresses it, and registers it in the TRE datastore as a new asset or a new version of an existing asset. It returns the DataFile object representing the ingested file\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.ingest_file_version","page":"API","title":"AHRI_TRE.ingest_file_version","text":"ingest_file_version(store::DataStore, file_path::AbstractString, datafile::DataFile)::DataFile\n\nIngest a new version of an existing data file in the TRE datastore.\n\nstore: The DataStore object containing connection details for the datastore.\nfile_path: The full path including the file name to the new file.\ndatafile: The existing DataFile object for which a new version is being ingested.\n\n\n\n\n\n","category":"function"},{"location":"api/#AHRI_TRE.ingest_redcap_project-Tuple{DataStore, AbstractString, AbstractString, Study, Domain}","page":"API","title":"AHRI_TRE.ingest_redcap_project","text":"ingest_redcap_project(api_url::AbstractString, api_token::AbstractString, study::Study, domain::Domain)\n\nRetrieves the REDCap project metadata and add the project variables to the TRE datastore. Downloads the REDCap project records in EAV format to a csv file and saves it to the data lake and creates an ingest transformation. Transforms the csv file from EAV (long) format to wide format dataset and registers the dataset in the TRE datastore.\n\napi_url: The URL of the REDCap API endpoint.\napi_token: The API token for the REDCap project.\nstudy: The Study object to associate with the REDCap project. \ndomain: The Domain object to associate with the REDCap project.\nvocabulary_prefix: The prefix for the vocabulary used in the REDCap project (default is \"REDCap\").\nforms: A vector of form names to include in the REDCap project (default is empty, meaning all forms).\nfields: A vector of field names to include in the REDCap project (default is empty, meaning all fields).\n\nReturns the DataFile object representing the ingested REDCap project data.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.list_domainentities-Tuple{DataStore, Int64}","page":"API","title":"AHRI_TRE.list_domainentities","text":"list_domainentities(store::DataStore, domain_id::Int)::DataFrame\n\nReturn a DataFrame containing all entities in the specified domain.\n\n'store' is the DataStore object containing the database connection.\n'domain_id' is the ID of the domain to list entities from.\n\nThe DataFrame will contain all columns from the entities table, ordered by name. This function is useful for retrieving all entities in a domain for further processing or display.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.list_domainrelations-Tuple{DataStore, Int64}","page":"API","title":"AHRI_TRE.list_domainrelations","text":"list_domainrelations(store::DataStore, domain_id::Int)::DataFrame\n\nReturn a DataFrame containing all entity relations in the specified domain.\n\n'store' is the DataStore object containing the database connection.\n'domain_id' is the ID of the domain to list entity relations from.\n\nThe DataFrame will contain all columns from the entityrelations table, ordered by name.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.list_study_transformations-Tuple{DataStore, Study}","page":"API","title":"AHRI_TRE.list_study_transformations","text":"list_study_transformations(store::DataStore, study::Study)::DataFrame\n\nReturn a DataFrame containing all transformations associated with assets in the specified study.\n\n'store' is the DataStore object containing the database connection.\n'study' is the Study object to list transformations from.\n\nThe DataFrame will contain all columns from the transformations table, ordered by date_created descending.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.load_query-Tuple{DataStore, DataSet, DBInterface.Connection, AbstractString}","page":"API","title":"AHRI_TRE.load_query","text":"load_query(datastore::DataStore, dataset::DataSet, source_conn::DBInterface.Connection, sql::AbstractString)\n\nLoad data from a source database connection into a dataset table in the TRE lake.\n\n'datastore' is the DataStore object containing the datastore and datalake connections.\n'dataset' is the DataSet object representing the target dataset.\n'source_conn' is the DBInterface.Connection object for the source database.\n'sql' is the SQL query string to retrieve data from the source database.\n\nThis function creates the target table in the TRE lake based on the dataset's variables\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.opendatastore","page":"API","title":"AHRI_TRE.opendatastore","text":"opendatastore(server::AbstractString, user::AbstractString, password::AbstractString, database::AbstractString,\nlake_data::Union{String,Nothing}=nothing, lake_db::Union{String,Nothing}=nothing,\nlake_user::Union{String,Nothing}=nothing, lake_password::Union{String,Nothing}=nothing; port::Integer=5432)\n\nOpen a PostgreSQL database connection to the datastore, and a DuckDB connection to the underlying ducklake\n\nserver: The PostgreSQL server hostname or IP\nuser: The PostgreSQL username\npassword: The PostgreSQL password\ndatabase: The PostgreSQL database name\nlake_data: Path to the DuckDB lake data directory\nlake_db: Name of the DuckDB lake metadata database\nlake_user: Username for the lake connection\nlake_password: Password for the lake connection\nport: The PostgreSQL server port (default 5432)\nreturns: A tuple of (PostgreSQL connection, DuckDB lake connection)\n\n\n\n\n\n","category":"function"},{"location":"api/#AHRI_TRE.opendatastore-Tuple{DataStore}","page":"API","title":"AHRI_TRE.opendatastore","text":"opendatastore(store::DataStore)::DataStore\n\nOpen a database connection in a DataStore object\n\nstore: A DataStore object with connection parameters\nreturns: The DataStore object with open connections\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.read_dataset-Tuple{DataStore, DataSet}","page":"API","title":"AHRI_TRE.read_dataset","text":"read_dataset(store::DataStore, dataset::DataSet)::AbstractDataFrame\n\nRead a dataset from the TRE datastore and return it as an AbstractDataFrame.\n\nstore: The DataStore object containing the datastore connection.\ndataset: The DataSet object representing the dataset to be read.\n\nThis function retrieves the dataset from the datastore and converts it to an AbstractDataFrame.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.read_dataset-Tuple{DataStore, String, String}","page":"API","title":"AHRI_TRE.read_dataset","text":"read_dataset(store::DataStore, study_name::String, dataset_name::String)::AbstractDataFrame\n\nRead a dataset from the TRE datastore by study name and dataset name.\n\nstore: The DataStore object containing the datastore connection.\nstudy_name: The name of the study containing the dataset.\ndataset_name: The name of the dataset to be read.\n\nThis function retrieves the study and dataset asset from the datastore, gets the latest version of the dataset, and converts it to an AbstractDataFrame.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.register_redcap_datadictionary-Tuple{DataStore, Int64, String, String}","page":"API","title":"AHRI_TRE.register_redcap_datadictionary","text":"register_redcap_datadictionary(store::DataStore,\ndomain_id::Int, redcap_url::String, redcap_token::String;\nforms=String[], vocabulary_prefix::String=\"\", use_transaction = true)::DataFrame\n\nField types: \"descriptive\",\"sql\",\"signature\",\"file\" are ignored. This function downloads the REDCap metadata, processes it, and registers variables in the given DataStore.     Database actions are wrapped in a transaction and rolled back on error, if use_transaction = true (default).\n\nstore: DataStore instance to use for database operations\ndomain_id: Domain ID to register variables under\nredcap_url: REDCap API URL\nredcap_token: API token for the REDCap project\nforms: Optional vector of form names to filter by (default: all forms)\nvocabulary_prefix: Optional prefix for vocabulary names (default: empty)\nuse_transaction: If true (default), wrap database actions in a transaction\n\nReturns a DataFrame with columns: fieldname, variableid, valuetypeid, vocabularyid, fieldtype, validation, label, note.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.save_dataset_variables!-Tuple{DataStore, DataSet}","page":"API","title":"AHRI_TRE.save_dataset_variables!","text":"save_dataset_variables!(store::DataStore, dataset::DataSet)::Nothing\n\nPersist the variable metadata attached to dataset.variables into the datastore metadata tables:\n\nUpserts rows in variables (unique on (domain_id, name))\nCreates/updates vocabularies and vocabulary_items for categorical/multiresponse variables\nLinks the dataset version to its variables in dataset_variables\n\nOn return, each Variable in dataset.variables will have variable_id (and where applicable vocabulary_id) populated.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.sql_meta-Tuple{Any, AbstractString, Int64, AbstractString}","page":"API","title":"AHRI_TRE.sql_meta","text":"sql_meta(conn, sql::AbstractString, domain_id::Int, flavour::AbstractString) -> Vector{Variable}\n\nExtract variable metadata from the columns of an SQL SELECT statement.\n\nArguments\n\nconn: Database connection (DBInterface.Connection)\nsql: SQL SELECT statement\ndomain_id: Domain ID to assign to variables\nflavour: Database flavour string (\"MSSQL\", \"DuckDB\", \"PostgreSQL\", \"SQLite\", or \"MySQL\")\n\nReturns\n\nVector of Variable structures, one for each column in the query result.\n\nThe function:\n\nExecutes the query with LIMIT 0 to get column metadata\nMaps SQL types to TRETYPE* constants\nDetects CATEGORY types for:\nENUM columns\nInteger columns referencing code tables (< 250 records)\nString columns with CHECK constraints listing allowed values\nPopulates Vocabulary for CATEGORY types\nRetrieves column comments as descriptions where available\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.sql_meta-Tuple{Any, AbstractString, Int64, DatabaseFlavour}","page":"API","title":"AHRI_TRE.sql_meta","text":"sql_meta(conn, sql::AbstractString, domain_id::Int, flavour::DatabaseFlavour) -> Vector{Variable}\n\nInternal implementation using typed database flavour for dispatch.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.sql_to_dataset-Tuple{DataStore, Study, Domain, String, DBInterface.Connection, AbstractString, String}","page":"API","title":"AHRI_TRE.sql_to_dataset","text":"sql_to_dataset(store::DataStore, study::Study, domain::Domain, dataset_name::String, conn, db_flavour::AbstractString, sql::String;\ndescription::String, replace::Bool=false, new_version::Union{VersionNumber,Nothing}=nothing)::DataSet\n\nTransform the result of an SQL query into a DataSet stored in the TRE DataStore.\n\nArguments\n\nstore: DataStore object\nstudy: Study object to associate the dataset with\ndomain: Domain object for the dataset\ndataset_name: Name of the dataset to create\nconn: Database connection to execute the SQL query\ndb_flavour: Database flavour type for metadata extraction\nsql: SQL query string to execute\ndescription: Description for the dataset asset/version\nreplace: If true, replace existing dataset with the same name by creating a new version\nnew_version: Optional Version object for the new dataset version\n\nReturns\n\nThe created DataSet object, or nothing on failure.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.transform_eav_to_dataset-Tuple{DataStore, DataFile}","page":"API","title":"AHRI_TRE.transform_eav_to_dataset","text":"transform_eav_to_dataset(store::DataStore, datafile::DataFile)::Union{DataSet, Nothing}\n\nTransform an EAV (Entity-Attribute-Value) data file into a dataset.\n\n'store' is the DataStore object containing the database connection.\n'datafile' is the DataFile object representing the EAV data file.\n'convert' indicates whether to convert data types based on variable definitions (default is true).\n\nThis function creates a new dataset in the database by pivoting the EAV data into a wide format. It aggregates multiple values for the same field per record into a single column. The dataset name is derived from the datafile's asset name, dropping the \"eav\" suffix if present. Returns a DataSet object representing the transformed data, or nothing if an error occurred. This function assumes the EAV data is stored in a csv table with columns: record, fieldname, and value.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.update_domain-Tuple{DataStore, Domain}","page":"API","title":"AHRI_TRE.update_domain","text":"update_domain(store::DataStore, domain::Domain)::Nothing\n\nUpdate an existing domain record.\n\n'store' is the DataStore object containing the database connection.\n'domain' is a Domain object containing the domain_id, name, uri, and description\nreturns nothing.\n\nThis function updates the domain record identified by domain.domainid with the new values for description and uri. It raises an error if domain.domainid is nothing.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.upsert_entity!-Tuple{DataStore, Entity}","page":"API","title":"AHRI_TRE.upsert_entity!","text":"upsert_entity!(store::DataStore, entity::Entity)::Entity\n\nCreate or update an entity record. If an entity with the same (domainid, name) already exists, it updates and returns its entityid.\n\n'entity' is an Entity object containing the domainid, name, description, ontologynamespace, and ontology_class.\n'store' is the DataStore object containing the database connection.\n\nIf the entity has a non-NULL ontologynamespace and ontologyclass, it must be unique with respect to the (domainid, name) combination. If the entity has a NULL ontologynamespace or ontologyclass, it must be unique with respect to the (domainid, name) combination,  allowing at most one row with a NULL ontologynamespace or ontologyclass for each (domain_id, name).  \n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.upsert_entityrelation!-Tuple{DataStore, EntityRelation}","page":"API","title":"AHRI_TRE.upsert_entityrelation!","text":"upsert_entityrelation!(store::DataStore, r::EntityRelation)::EntityRelation\n\nCreate or update an entity relation record. If a relation with the same (domainid, name) already exists, it updates and returns its entityrelationid.\n\n'r' is an EntityRelation object containing the entityid1, entityid2, domainid, name, description, ontologynamespace, and ontology_class.\n'store' is the DataStore object containing the database connection.\n\nIf the relation has a non-NULL ontologynamespace and ontologyclass, it must be unique with respect to the (domainid, name) combination. If the relation has a NULL ontologynamespace or ontologyclass, it must be unique with respect to the (domainid, name) combination, allowing at most one row with a NULL ontologynamespace or ontologyclass for each (domainid, name). This function returns the updated or newly created EntityRelation object with the entityrelationid and uuid set.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.upsert_study!-Tuple{DataStore, Study}","page":"API","title":"AHRI_TRE.upsert_study!","text":"upsert_study!(store::DataStore, study::Study)::Study\n\nCreate or update a study record. If a study with the same name already exists, it updates and returns the study. Otherwise, it inserts a new row and returns the new study. If study.study_id is nothing, it inserts a new study and lets PostgreSQL assign\n\n'study' is a Study object containing the name, description, externalid, and studytype_id.\n'store' is the DataStore object containing the database connection.\n\nIf the study name is required and it must be unique.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.upsert_variable!-Tuple{DataStore, Int64, String}","page":"API","title":"AHRI_TRE.upsert_variable!","text":"upsert_variable!(db, domain_id::Int, name::String; value_type_id::Int, vocabulary_id::Union{Nothing,Int}=nothing, description::Union{Missing,String}=missing) -> Int\n\nUpserts into variables on (domainid, name). Returns variableid.\n\n'datastore' is the DataStore object containing the database connection.\n'domain_id' is the ID of the domain to which the variable belongs.\n'name' is the name of the variable.\n'valuetypeid' is the ID of the value type for the variable.\n'value_format' is an optional format string for the variable's value type (default is missing).\n'vocabulary_id' is an optional ID of the vocabulary associated with the variable (default is missing).\n'description' is an optional description of the variable (default is missing).\n'note' is an optional note for the variable (default is missing).\n'keyrole' is an optional key role for the variable (default is \"none\").\n'ontology_namespace' is an optional ontology namespace for the variable (default is missing).\n'ontology_class' is an optional ontology class for the variable (default is missing).\n\nReturns the variable_id of the inserted or updated variable.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.ColumnInfo","page":"API","title":"AHRI_TRE.ColumnInfo","text":"ColumnInfo\n\nInternal structure to hold column metadata extracted from query results.\n\n\n\n\n\n","category":"type"},{"location":"api/#AHRI_TRE._normalize_remote-Tuple{AbstractString}","page":"API","title":"AHRI_TRE._normalize_remote","text":"_normalize_remote(url::AbstractString)\n\nNormalize a git remote URL by converting SSH format to HTTPS format.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE._strip_html-Tuple{AbstractString}","page":"API","title":"AHRI_TRE._strip_html","text":"_strip_html(text::AbstractString) -> String\n\nRemove HTML tags, script/style blocks, and decode a few common entities. Collapse whitespace to single spaces and trim ends. Used to clean REDCap rich-text labels before persisting them as variable descriptions.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.caller_file_runtime","page":"API","title":"AHRI_TRE.caller_file_runtime","text":"caller_file_runtime()\n\nReturn the file path of the script that called this function at runtime.   'level' indicates how many levels up the call stack to go (default 1 = immediate caller).\n\n\n\n\n\n","category":"function"},{"location":"api/#AHRI_TRE.convert_missing_to_string!-Tuple{DataFrames.DataFrame}","page":"API","title":"AHRI_TRE.convert_missing_to_string!","text":"convert_missing_to_string!(df::DataFrame)\n\nIf the column type is Missing, convert the column eltype to Union{String, Missing}.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.create_dataset_meta-Tuple{DataStore, Study, String, String, DataFile}","page":"API","title":"AHRI_TRE.create_dataset_meta","text":"create_dataset_meta(store::DataStore, study::Study, dataset_name::String, description::String, datafile::DataFile)::DataSet\n\nCreate a new dataset metadata object from an EAV data file.\n\n'store' is the DataStore object containing the database connection.\n'study' is the Study object to associate with the dataset.\n'dataset_name' is the name of the dataset to create.\n'description' is a description for the dataset.\n'datafile' is the DataFile object representing the EAV data file that the dataset is derived from.\n\nThis function creates a new dataset asset and version, collects variable metadata from the EAV data file, and returns a DataSet object containing the dataset metadata.\n\nAssumptions\n\nThe EAV data is stored in a csv table with columns: record, field_name, and value.\nThe variable meta data is already defined in the datastore for the study, variables not found will be skipped.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.create_duckdb_table_sql-Tuple{AbstractString, Vector{AHRI_TRE.Variable}}","page":"API","title":"AHRI_TRE.create_duckdb_table_sql","text":"create_duckdb_table_sql(table_name::AbstractString, variables::Vector{Variable})::String\n\nGenerate a CREATE TABLE SQL statement for DuckDB based on the provided variables.\n\n'table_name' is the name of the table to create.\n'variables' is a vector of Variable objects defining the table schema.\n\nThis function returns a SQL string that can be executed to create the table in DuckDB.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.createassets-Tuple{DBInterface.Connection}","page":"API","title":"AHRI_TRE.createassets","text":"createassets(conn::DBInterface.Connection)\n\nCreate tables to record data assets, rows, data and links to the transformations that use/created the assets A digital asset is a dataset or file that is stored in the TRE datalake.\n\nThe asset_versions table tracks different versions of the assets, with a version label and note.    An asset can have multiple versions, and the latest version is flagged by the is_latest flag set as TRUE.\nThe datasets table is a type of asset that is linked to the asset_versions table and managed through the ducklake extension.\nThe datafiles table stores references to files in the data lake, with metadata such as compression, encryption, storage URI, format, and digest.\nThe transformation_inputs and transformation_outputs tables link transformations to the asset versions they use or produce.\nThe dataset_variables table links datasets to the variables (columns) they contain, representing the schema of the dataset.\nThe data_asset_entities table links assets to entity instances, allowing for tracking which entities are associated with specific assets.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.createdatabase-Tuple{DBInterface.Connection}","page":"API","title":"AHRI_TRE.createdatabase","text":" createdatabase(conn::DBInterface.Connection; replace=false)\n\nCreate the AHRI_TRE database schema in PostgreSQL.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.createentities-Tuple{DBInterface.Connection}","page":"API","title":"AHRI_TRE.createentities","text":"createentities(conn)\n\nCreate tables to store entities, entity relations, entity instances, and relation instances. Entities represent individuals, households, or other entities in the TRE. Entity relations represent relationships between entities, such as family or household relationships. Entity instances represent specific instances of entities in a study, allowing for tracking of entities across studies.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.createmapping-Tuple{DBInterface.Connection}","page":"API","title":"AHRI_TRE.createmapping","text":"createmapping(conn::DBInterface.Connection)\n\nCreate the table required for variable mapping. This table is used to map variables from one instrument to another. The table is created in the database provided as an argument. The variable mapping is based on the PyCrossVA approach.\n\nThe relationship to the PyCrossVA configuration file columns:\n\nNew Column Name = destinationid - the variableid of the new column\nNew Column Documentation = Stored in the variable table\nstudy Column ID = fromid - the variableid of the study variable\nstudy Column Documentation = will be in the variables table\nRelationship = operator - the operator to be used to create the new variable\nCondition = operants - the operants to be used with the operator\nPrerequisite = prerequisiteid - the variableid of the prerequisite variable\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.createstudies-Tuple{DBInterface.Connection}","page":"API","title":"AHRI_TRE.createstudies","text":"createstudies(conn::DBInterface.Connection)\n\nCreate the studies and study_types tables in PostgreSQL datastore\n\nconn: The database connection\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.createtransformations-Tuple{DBInterface.Connection}","page":"API","title":"AHRI_TRE.createtransformations","text":"createtransformations(conn::DBInterface.Connection)\n\nCreate tables to record data transformations and ingests Transformation types:\n\ningest: Ingesting data into the TRE\ntransform: Transforming existing data in the TRE\nentity: Creating entity-instances from ingested or transformed data\nexport: Exporting datasets from the TRE\nrepository: Transferring datasets to the associated data repository\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.createvariables-Tuple{DBInterface.Connection}","page":"API","title":"AHRI_TRE.createvariables","text":"createvariables(conn)\n\nCreate tables to record value types, variables and vocabularies\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.emptydir-Tuple{AbstractString}","page":"API","title":"AHRI_TRE.emptydir","text":"emptydir(path; create=true, retries=3, wait=0.2)\n\nEnsure path exists (if create=true), then remove all files/subdirs inside it, keeping path itself. Retries briefly to tolerate transient files.\n\nSafety: refuses to operate on the filesystem root \"/\".\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.ensure_mssql_driver_registered","page":"API","title":"AHRI_TRE.ensure_mssql_driver_registered","text":"ensure_mssql_driver_registered(driver_name::AbstractString=\"ODBC Driver 18 for SQL Server\")\n\nEnsure the MSSQL ODBC driver is registered with ODBC.jl. On Linux/macOS systems, this checks if the driver is registered and attempts to register it from system locations if not found.\n\nThe function searches for drivers in the following order:\n\nAlready registered with ODBC.jl\nSystem ODBC configuration files (/etc/odbcinst.ini)\nCommon installation directories\n\nReturns true if driver is available, false otherwise.\n\n\n\n\n\n","category":"function"},{"location":"api/#AHRI_TRE.ensure_vocabulary!-Tuple{DataStore, String, String, AbstractVector{<:AHRI_TRE.AbstractVocabularyItem}}","page":"API","title":"AHRI_TRE.ensure_vocabulary!","text":"ensure_vocabulary!(store::DataStore, vocab_name::String, description::String, items::AbstractVector{<:AbstractVocabularyItem})::Int\n\nCreates or reuses a vocabulary by name, and (re)loads items idempotently.\n\n'store' is the DataStore object containing the database connection.\n'vocab_name' is the name of the vocabulary to ensure.\n'description' is a description of the vocabulary.\n'items' is a vector of AbstractVocabularyItem objects to load into the vocabulary.\n\nReturns vocabulary_id.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.ensure_vocabulary!-Tuple{DataStore, Vocabulary}","page":"API","title":"AHRI_TRE.ensure_vocabulary!","text":"ensure_vocabulary!(db, vocab::Vocabulary) -> Int\n\nEnsure that vocab exists in the datastore vocabularies table and (re)load its items into vocabulary_items.\n\nReturns the vocabulary_id.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.extract_table_from_sql-Tuple{AbstractString}","page":"API","title":"AHRI_TRE.extract_table_from_sql","text":"extract_table_from_sql(sql::AbstractString) -> Union{String, Nothing}\n\nAttempt to extract the main table name from a simple SQL SELECT statement. This is a best-effort extraction and may not work for complex queries.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.file_uri_to_path-Tuple{AbstractString}","page":"API","title":"AHRI_TRE.file_uri_to_path","text":"file_uri_to_path(uri::AbstractString) -> String\n\nConvert a file:// URI to a local filesystem path (Windows or Unix). Handles:\n\nfile:///C:/...        -> C:... (Windows)\nfile://server/share   -> \\server\\share (Windows UNC)\nfile:///home/me/...   -> /home/me/... (Unix)\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.find_mssql_driver_in_directory-Tuple{}","page":"API","title":"AHRI_TRE.find_mssql_driver_in_directory","text":"find_mssql_driver_in_directory() -> Union{String,Nothing}\n\nScan common installation directories for Microsoft ODBC Driver libraries. Returns the path to the first valid driver found, or nothing if none found.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.find_system_odbc_driver-Tuple{AbstractString}","page":"API","title":"AHRI_TRE.find_system_odbc_driver","text":"find_system_odbc_driver(driver_name::AbstractString) -> Union{String,Nothing}\n\nSearch system ODBC configuration files for the specified driver and return its path. Checks /etc/odbcinst.ini on Linux and /opt/homebrew/etc/odbcinst.ini on macOS.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_assetversions-Tuple{DataStore, Asset}","page":"API","title":"AHRI_TRE.get_assetversions","text":"get_assetversions(store::DataStore, asset::Asset)::Vector{AssetVersion}\n\nReturn a vector of AssetVersion objects for the specified asset.\n\n'store' is the DataStore object containing the database connection.\n'asset' is the Asset object for which to retrieve versions.\n\nIf no versions are found, it returns an empty vector.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_check_constraint_values-Tuple{Any, AbstractString, AbstractString, DatabaseFlavour}","page":"API","title":"AHRI_TRE.get_check_constraint_values","text":"get_check_constraint_values(conn, table_name::AbstractString, column_name::AbstractString,\n                             flavour::DatabaseFlavour) -> Vector{VocabularyItem}\n\nExtract allowed values from CHECK constraints on a column.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_code_table_vocabulary-Tuple{Any, AbstractString, AbstractString, DatabaseFlavour}","page":"API","title":"AHRI_TRE.get_code_table_vocabulary","text":"get_code_table_vocabulary(conn, table_name::AbstractString, pk_column::AbstractString,\n                           flavour::DatabaseFlavour) -> Vector{VocabularyItem}\n\nExtract vocabulary items from a code/lookup table. Uses the primary key as value, first string column as code, and description column if present.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_column_comment-Tuple{Any, AbstractString, AbstractString, Union{Nothing, AbstractString}, DatabaseFlavour}","page":"API","title":"AHRI_TRE.get_column_comment","text":"get_column_comment(conn, table_name::AbstractString, column_name::AbstractString,\n                   schema_name::Union{AbstractString,Nothing}, flavour::DatabaseFlavour) -> Union{String,Missing}\n\nGet the comment/description for a column from the database metadata.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_column_type_info-Tuple{Any, AbstractString, DatabaseFlavour}","page":"API","title":"AHRI_TRE.get_column_type_info","text":"get_column_type_info(conn, sql::AbstractString, flavour::DatabaseFlavour) -> Vector{Tuple{String,String,Union{String,Nothing}}}\n\nGet detailed column type information from the database for a query. Returns vector of (columnname, datatype, table_name) tuples.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_datafile-Tuple{DataStore, Base.UUID}","page":"API","title":"AHRI_TRE.get_datafile","text":"get_datafile(store::DataStore, datafile_id::UUID)::Union{DataFile,Nothing}\n\nRetrieve a data file from the datastore by its ID.\n\nstore: The DataStore object containing the database connection.\ndatafile_id: The UUID of the data file to retrieve.\n\nThis function returns a DataFile object if found, or nothing if no data file with the specified ID exists.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_datafile_meta-Tuple{DataStore, AssetVersion}","page":"API","title":"AHRI_TRE.get_datafile_meta","text":"get_datafile_meta(store::DataStore, assetversion::AssetVersion)::Union{DataFile,Nothing}\n\nGet metadata for a DataFile associated with the specified AssetVersion.\n\nstore: The DataStore object containing connection details for the datastore.\nassetversion: The AssetVersion object for which to retrieve the DataFile metadata.\n\nIf no DataFile is found, it returns nothing.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_datafilename-Tuple{DataFile}","page":"API","title":"AHRI_TRE.get_datafilename","text":"get_datafilename(datafile::DataFile)::String\n\nGet a valid filename for a datafile based on its asset name and version\n\ndatafile: The DataFile object for which to generate the filename.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_datalake_file_path-Tuple{DataStore, Study, String, AbstractString, VersionNumber}","page":"API","title":"AHRI_TRE.get_datalake_file_path","text":"get_datalake_file_path(store::DataStore, study::Study, asset_name::String, file_path::AbstractString, version::VersionNumber)::String\n\nGet the destination file path in the data lake for a given file to be ingested.\n\nstore: The DataStore object containing connection details for the datastore and data lake.\nstudy: The Study object to associate with the ingested file.\nasset_name: The name of the asset to which the file will be attached. Must comply with xsd:NCName restrictions.\nfile_path: The full path including the file name to the file to be ingested.\nversion: The version number for the file to be ingested.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_eav_variable_names-Tuple{DataStore, DataFile}","page":"API","title":"AHRI_TRE.get_eav_variable_names","text":"get_eav_variable_names(store::DataStore, datafile::DataFile)::DataFrame\n\nReturn a DataFrame containing all distinct EAV variable names from the specified datafile.\n\n'store' is the DataStore object containing the database connection.\n'datafile' is the DataFile object for which to retrieve EAV variables.\n\nThe DataFrame will contain a single column 'field_name' with distinct variable names ordered alphabetically.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_enum_values-Tuple{Any, AbstractString, DatabaseFlavour}","page":"API","title":"AHRI_TRE.get_enum_values","text":"get_enum_values(conn, type_name::AbstractString, flavour::DatabaseFlavour) -> Vector{VocabularyItem}\n\nGet the values for an enum type.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_foreign_key_reference-Tuple{Any, AbstractString, AbstractString, DatabaseFlavour}","page":"API","title":"AHRI_TRE.get_foreign_key_reference","text":"get_foreign_key_reference(conn, table_name::AbstractString, column_name::AbstractString,\n                          flavour::DatabaseFlavour) -> Union{Nothing,Tuple{String,String}}\n\nReturn the referenced table/column for a foreign key on table_name.column_name, or nothing if no foreign key relationship can be determined.\n\nDatabase-specific overrides implement this for each flavour.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_latest_version-Tuple{Asset}","page":"API","title":"AHRI_TRE.get_latest_version","text":"get_latest_version(asset::Asset)::Union{AssetVersion,Nothing}\n\nReturn the latest AssetVersion for the specified asset.\n\n'asset' is the Asset object for which to retrieve the latest version.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_latest_version-Tuple{DataStore, Base.UUID}","page":"API","title":"AHRI_TRE.get_latest_version","text":"get_latest_version(store::DataStore, asset_id::UUID)::Union{AssetVersion,Nothing}\n\nReturn the latest AssetVersion for the specified asset_id in the DataStore.\n\n'store' is the DataStore object containing the database connection.\n'asset_id' is the UUID of the asset for which to retrieve the latest version.\n\nIf no latest version is found, it returns nothing.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_namedkey-Tuple{DBInterface.Connection, Any, Any, Any}","page":"API","title":"AHRI_TRE.get_namedkey","text":"get_namedkey(db::DBInterface.Connection, table, key, keycol)\n\nReturn the integer key from table table in column keycol (keycol must be a Symbol) for key with name key\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_original_column_type-Tuple{Any, AbstractString, AbstractString, DatabaseFlavour}","page":"API","title":"AHRI_TRE.get_original_column_type","text":"get_original_column_type(conn, table_name::AbstractString, column_name::AbstractString,\n                          flavour::DatabaseFlavour) -> Union{String,Nothing}\n\nGet the original column type from the database schema.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_query_columns-Tuple{Any, AbstractString, AHRI_TRE.MSSQLFlavour}","page":"API","title":"AHRI_TRE.get_query_columns","text":"get_query_columns(conn, sql::AbstractString, ::MSSQLFlavour) -> Vector{ColumnInfo}\n\nMSSQL-specific implementation using sys.dmexecdescribefirstresult_set to get rich column metadata including source table and schema information.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_query_columns-Tuple{Any, AbstractString, DatabaseFlavour}","page":"API","title":"AHRI_TRE.get_query_columns","text":"get_query_columns(conn, sql::AbstractString, flavour::DatabaseFlavour) -> Vector{ColumnInfo}\n\nExecute a query with LIMIT 0 or equivalent to get column metadata without fetching data.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_study_variables_df-Tuple{DataStore, Study}","page":"API","title":"AHRI_TRE.get_study_variables_df","text":"get_study_variables_df(store::DataStore, study::Study; domain::Union{Domain,Nothing}=nothing)::DataFrame\n\nReturn a DataFrame containing all variables associated with the specified study.\n\n'store' is the DataStore object containing the database connection.\n'study' is the Study object to list variables from.\n'domain' is an optional Domain object to filter variables by domain.\n\nIf domain is provided, only variables from that domain are returned.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_studyid-Tuple{DataStore, AbstractString}","page":"API","title":"AHRI_TRE.get_studyid","text":"get_studyid(db::DBInterface.Connection, name)\n\nReturn the source_id of source name, returns missing if source doesn't exist\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_table-Tuple{DBInterface.Connection, String}","page":"API","title":"AHRI_TRE.get_table","text":"get_table(conn::DBInterface.Connection, table::String)::AbstractDataFrame\n\nRetrieve table table as a DataFrame from conn\n\nconn: The database connection\ntable: The name of the table to retrieve\nreturns: A DataFrame containing the table data\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_table_columns-Tuple{Any, AbstractString, DatabaseFlavour}","page":"API","title":"AHRI_TRE.get_table_columns","text":"get_table_columns(conn, table_name::AbstractString, flavour::DatabaseFlavour) -> Vector{ColumnInfo}\n\nGet column information for a table.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_variable_id-Tuple{DBInterface.Connection, Any, Any}","page":"API","title":"AHRI_TRE.get_variable_id","text":"get_variable_id(db::DBInterface.Connection, domain, name)\n\nReturns the `variable_id` of variable named `name` in domain with id `domain`\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.get_vocabulary-Tuple{DataStore, Int64}","page":"API","title":"AHRI_TRE.get_vocabulary","text":"get_vocabulary(store::DataStore, vocabulary_id::Int)::Union{Vocabulary,Nothing}\n\nReturn a Vocabulary object by its vocabulary_id in the specified DataStore.\n\n'store' is the DataStore object containing the database connection.\n'vocabulary_id' is the ID of the vocabulary to retrieve.\n\nIf no vocabulary is found, it returns nothing. If a vocabulary is found, it returns a Vocabulary object with its items populated.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.git_commit_info","page":"API","title":"AHRI_TRE.git_commit_info","text":"git_commit_info(dir::Union{AbstractString,Nothing}=nothing; short::Bool=true, script_path::Union{AbstractString,Nothing}=nothing)\n\nReturn version control information about the currently executing script for use in transformations.\n\ndir: Directory to search for the git repository. If nothing, it is derived from script_path when available, otherwise pwd().\nshort: Whether to return a short commit hash (default is true, returns first 7 characters of the hash).\nscript_path: The path to the script being executed. If nothing, it is resolved at runtime from the caller (or Base.PROGRAM_FILE when available).\n\nReturns a tuple with:\n\nrepo_url: The URL of the git repository (or missing if not found).\ncommit: The commit hash (or missing if not found).\nscript_relpath: The relative path of the script from the repository root (or missing if not found).\n\nThis function normalizes SSH remotes to HTTPS format. If the script is not in a git repository, repo_url and commit are missing. If a script path can be determined, script_relpath is set to the absolute script path.\n\n\n\n\n\n","category":"function"},{"location":"api/#AHRI_TRE.initstudytypes-Tuple{}","page":"API","title":"AHRI_TRE.initstudytypes","text":"initstudytypes()\n\nInitialize the study_types table with standard study types\n\nreturns: SQL string to insert the study types\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.initvalue_types-Tuple{}","page":"API","title":"AHRI_TRE.initvalue_types","text":"initvalue_types()\n\nAdd default value types\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.insertdata-Tuple{DBInterface.Connection, Any, Any, Any}","page":"API","title":"AHRI_TRE.insertdata","text":"insertdata(conn::DBInterface.Connection, table, columns, values)\n\nInsert a set of values into a table, columns list the names of the columns to insert, and values the values to insert\n\nconn: The database connection\ntable: The name of the table to insert into\ncolumns: A vector of column names to insert\nvalues: A vector of values corresponding to the columns to insert\nreturns: nothing\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.insertwithidentity-Tuple{DBInterface.Connection, Any, Any, Any}","page":"API","title":"AHRI_TRE.insertwithidentity","text":"insertwithidentity(conn::DBInterface.Connection, table, columns, values)\n\nInsert a record, returning the identity column value\n\nconn: The database connection\ntable: The name of the table to insert into\ncolumns: A vector of column names to insert\nvalues: A vector of values corresponding to the columns to insert\nreturns: The value of the identity column for the inserted record\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.is_code_table-Tuple{Any, AbstractString, AbstractString, DatabaseFlavour}","page":"API","title":"AHRI_TRE.is_code_table","text":"is_code_table(conn, table_name::AbstractString, pk_column::AbstractString, flavour::DatabaseFlavour) -> Bool\n\nCheck if a table qualifies as a code/lookup table:\n\nHas less than 250 records\nHas a primary key column matching the specified column name\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.is_enum_type-Tuple{Any, AbstractString, DatabaseFlavour}","page":"API","title":"AHRI_TRE.is_enum_type","text":"is_enum_type(conn, type_name::AbstractString, flavour::DatabaseFlavour) -> Bool\n\nCheck if a type is an enum type.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.is_ncname-Tuple{AbstractString}","page":"API","title":"AHRI_TRE.is_ncname","text":"is_ncname(s::AbstractString) -> Bool\n\nReturn true if s is a valid NCName (no colon, proper start char, allowed name chars).\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.julia_type_to_sql_string-Tuple{Type}","page":"API","title":"AHRI_TRE.julia_type_to_sql_string","text":"julia_type_to_sql_string(T::Type) -> String\n\nConvert a Julia type to a SQL type string for type mapping.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.lines-Tuple{Any}","page":"API","title":"AHRI_TRE.lines","text":"lines(str)\n\nReturns an array of lines in str \n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.list_study_assets_df-Tuple{DataStore, Study}","page":"API","title":"AHRI_TRE.list_study_assets_df","text":"list_study_assets_df(store::DataStore, study::Study; include_versions=true)::DataFrame\n\nReturn a DataFrame containing all assets in the specified study.\n\n'store' is the DataStore object containing the database connection.\n'study' is the Study object to list assets from.\n'include_versions' is a boolean flag indicating whether to include asset versions in the DataFrame.\n\nIf include_versions is true, the DataFrame will include asset version details\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.make_asset-Tuple{DataStore, DataFrames.DataFrameRow, Study}","page":"API","title":"AHRI_TRE.make_asset","text":"make_asset(row::DataFrameRow, study::Study; include_versions=true)::Asset\n\nHelper function to create an Asset object from a DataFrameRow and a Study.\n\nstore is the DataStore object containing the database connection.\nrow is a DataFrameRow containing asset data.\nstudy is the Study object to associate with the asset.\ninclude_versions is a boolean flag indicating whether to include asset versions in the Asset object.\n\nThis function returns an Asset object with its versions populated if requested.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.makeparams-Tuple{Any}","page":"API","title":"AHRI_TRE.makeparams","text":"makeparam(s)\n\nReturn a parameterized string for SQL queries\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.map_sql_type_to_tre-Tuple{AbstractString, DatabaseFlavour}","page":"API","title":"AHRI_TRE.map_sql_type_to_tre","text":"map_sql_type_to_tre(sql_type::AbstractString, flavour::DatabaseFlavour) -> Int\n\nMap a SQL data type string to the corresponding TRETYPE* constant. Returns the TRE type ID.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.map_value_type-Tuple{AbstractString, Union{Missing, AbstractString}}","page":"API","title":"AHRI_TRE.map_value_type","text":"map_value_type(field_type::String, validation::Union{Missing,String}) -> Int\n\nREDCap fieldtype and validation -> TRE valuetype_id.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.parse_check_constraint_values-Tuple{AbstractString, AbstractString}","page":"API","title":"AHRI_TRE.parse_check_constraint_values","text":"parse_check_constraint_values(constraint_def::AbstractString, column_name::AbstractString) -> Vector{VocabularyItem}\n\nParse a CHECK constraint definition to extract allowed string values.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.parse_flavour-Tuple{AbstractString}","page":"API","title":"AHRI_TRE.parse_flavour","text":"parse_flavour(flavour::AbstractString) -> DatabaseFlavour\n\nConvert a string database flavour name to the corresponding type for dispatch.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.parse_in_list_values-Tuple{AbstractString}","page":"API","title":"AHRI_TRE.parse_in_list_values","text":"parse_in_list_values(values_str::AbstractString) -> Vector{VocabularyItem}\n\nParse a comma-separated list of quoted values into VocabularyItems.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.parse_redcap_choices-Tuple{AbstractString}","page":"API","title":"AHRI_TRE.parse_redcap_choices","text":"parse_redcap_choices(s::AbstractString) -> Vector{NamedTuple{(:value,:code,:description),Tuple{Int,String,Union{String,Missing}}}}\n\nParses \"1, Male | 2, Female\" into a vector of items.\n\nvalue: Int (left id)\ncode:  String (tokenized label; spaces -> _)\ndescription: original label\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.path_to_file_uri-Tuple{AbstractString}","page":"API","title":"AHRI_TRE.path_to_file_uri","text":"path_to_file_uri(path::AbstractString) -> String\n\nConvert a local filesystem path (Windows or Unix) to a file:// URI.\n\nWindows local path:   C:\\Users\\me\\file.txt   -> file:///C:/Users/me/file.txt\nWindows UNC path:     \\srv\\share\\f.txt     -> file://srv/share/f.txt\nUnix path:            /home/me/file.txt         -> file:///home/me/file.txt\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.prepare_datafile-Tuple{AbstractString, String}","page":"API","title":"AHRI_TRE.prepare_datafile","text":"prepare_datafile(file_path::AbstractString, edam_format::String; compress::Bool=false, encrypt::Bool=false) -> DataFile\n\nPrepare a DataFile for registration: validate path, optionally compress, compute digest and populate DataFile fields.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.prepareinsertstatement-Tuple{DBInterface.Connection, Any, Any}","page":"API","title":"AHRI_TRE.prepareinsertstatement","text":"prepareinsertstatement(conn::DBInterface.Connection, table, columns)\n\nPrepare an insert statement for PostgreSQL into table for columns     - conn: The database connection     - table: The name of the table to insert into     - columns: A vector of column names to insert into\n\nreturns: A prepared statement object\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.prepareselectstatement-Tuple{DBInterface.Connection, Any, Vector{String}, Vector{String}}","page":"API","title":"AHRI_TRE.prepareselectstatement","text":"prepareselectstatement(conn::DBInterface.Connection, table, columns::Vector{String}, filter::Vector{String})\n\nReturn a statement to select columns from a table, with 0 to n columns to filter on\n\nconn: The database connection\ntable: The name of the table to query\ncolumns: A vector of column names to select\nfilter: A vector of column names to filter on\nreturns: A prepared statement object\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.quote_ident-Tuple{AbstractString}","page":"API","title":"AHRI_TRE.quote_ident","text":"quote_ident(name::AbstractString)\n\nReturn a quoted identifier for SQL queries.\n\n'name' is the identifier to quote, typically a table or column name.\n\nThis function wraps the identifier in double quotes and escapes any existing double quotes by doubling them.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.quote_identifier-Tuple{AbstractString, DatabaseFlavour}","page":"API","title":"AHRI_TRE.quote_identifier","text":"quote_identifier(name::AbstractString, flavour::DatabaseFlavour) -> String\n\nQuote an identifier appropriately for the database flavour.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.quote_sql_str-Tuple{AbstractString}","page":"API","title":"AHRI_TRE.quote_sql_str","text":"quote_sql_str(s::AbstractString)\n\nReturn a quoted SQL string for use in SQL queries.\n\n's' is the string to quote.\n\nThis function wraps the string in single quotes and escapes any existing single quotes by doubling them.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.redcap_export_eav-Tuple{AbstractString, AbstractString}","page":"API","title":"AHRI_TRE.redcap_export_eav","text":"redcap_export_eav(api_url::AbstractString, api_token::AbstractString; forms::Vector{String}=String[], fields::Vector{String}=String[],lake_root = ENV[\"TRE_LAKE_PATH\"], decode::Bool=false)::String\n\nExports REDCap data in EAV format (Entity-Attribute-Value) as a CSV file.\n\napi_url: REDCap API URL\napi_token: API token\nforms: Optional vector of form names to export (default: all forms)\nfields: Optional vector of field names to export (default: all fields)\nlakeroot: Root directory for saving the export file (default: TRELAKE_PATH environment variable)\ndecode: If true, decode the response body from ISO-8859-2 to UTF-8 before saving\n\nReturns the path to the saved CSV file. REDCap Bug: The API ignores the fields parameter and returns all fields, irrespective of the fields parameter.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.redcap_fields-Tuple{AbstractString, AbstractString}","page":"API","title":"AHRI_TRE.redcap_fields","text":"redcap_fields(api_url::AbstractString, api_token::AbstractString;\nforms::Union{Nothing,Vector{String}}=nothing,\ninclude_nondata::Bool=false)::Vector{String}\n\nFetches REDCap metadata fields, optionally filtering by forms and including non-data fields. Returns a vector of field names.\n\nurl: REDCap API URL\ntoken: API token\nforms: Optional vector of form names to filter by (default: all forms)\ninclude_nondata: If true, include non-data fields like descriptive, file, sql, signature\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.redcap_metadata-Tuple{AbstractString, AbstractString}","page":"API","title":"AHRI_TRE.redcap_metadata","text":"redcap_metadata(url::AbstractString, token::AbstractString;\n                forms::Union{Nothing,Vector{String}}=nothing) -> DataFrame\n\nDownloads REDCap data dictionary (metadata) as a DataFrame.\n\nurl: REDCap API URL\ntoken: API token\nforms: Optional vector of form names to filter by (default: all forms)\nfields: Optional vector of field names to filter by (default: all fields)\n\nREDCap Bug: The API ignores the fields parameter and returns all fields, irrespective of the fields parameter. Returns a DataFrame with columns: fieldname, fieldtype, textvalidationtypeorshowslidernumber, selectchoicesorcalculations, fieldlabel, field_note.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.redcap_post-Tuple{Any, AbstractDict}","page":"API","title":"AHRI_TRE.redcap_post","text":"redcap_post(body::Dict)::HTTP.Response\n\nDo a POST request to the REDCap API with the given body.\n\napi_url: REDCap API URL\nbody: Dictionary containing the POST parameters\nretry: Number of retry attempts in case of failure (default: 5)\n\nReturns the HTTP response object.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.redcap_post_tofile-Tuple{Any, AbstractDict, String}","page":"API","title":"AHRI_TRE.redcap_post_tofile","text":"redcap_post_tofile(api_url, body::AbstractDict, outputfile::String; decode::Bool=false, retry=5)::Bool\n\nDo a POST request to the REDCap API with the given body and save the response to a file.\n\napi_url: REDCap API URL\nbody: Dictionary containing the POST parameters\noutputfile: File path to save the response\ndecode: If true, decode the response body from ISO-8859-2 to UTF-8 before saving\nretry: Number of retry attempts in case of failure (default: 5)\n\nReturns true if successful, false otherwise.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.redcap_project_info-Tuple{AbstractString, AbstractString}","page":"API","title":"AHRI_TRE.redcap_project_info","text":"redcap_project_info(url, token; raw=false) -> NamedTuple | JSON3.Object\n\nFetch high-level REDCap project information (title, purpose, status, etc.). When raw=true, return the parsed JSON3.Object directly. When raw=false (default), return a NamedTuple with symbol keys suitable for constructing a DataFrame or logging.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.redcap_project_info_df-Tuple{AbstractString, AbstractString}","page":"API","title":"AHRI_TRE.redcap_project_info_df","text":"redcap_project_info_df(url, token) -> DataFrame\n\nConvenience wrapper returning a single-row DataFrame with project metadata.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.register_datafile-Tuple{DataStore, DataFile}","page":"API","title":"AHRI_TRE.register_datafile","text":"register_datafile(store::DataStore, datafile::DataFile)\n\nRegister a DataFile in the TRE datastore. The assetversion must already exist in the datastore.\n\nstore: The Datastore object containing connection details for the datastore.\ndatafile: The DataFile object to register, which must have a valid assetversion.\n\nThis function will insert the datafile into the database and associate it with the specified asset version.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.register_dataset-Tuple{DataStore, DataSet}","page":"API","title":"AHRI_TRE.register_dataset","text":"register_dataset(store::DataStore, dataset::DataSet)::Nothing\n\nRegister a Dataset in the TRE datastore.\n\nstore: The DataStore object containing connection details for the datastore.\ndataset: The Dataset object to register, which must have a valid dataset_id.\n\nThis function will insert the dataset into the database.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.replace_database-Tuple{DBInterface.Connection, String, String, String}","page":"API","title":"AHRI_TRE.replace_database","text":"replace_database(conn::DBInterface.Connection, database::String, user::String, password::String)\n\nReplace the existing database with a new one, dropping it first if it exists.      This function is used to reset the database, typically for development or testing purposes.     Creates the user role if it does not exist, and set the rolle as the owner of the new database. NB: ONLY USE THIS FUNCTION IN DEVELOPMENT OR TESTING ENVIRONMENTS,     as it will drop the existing database, lake and all its contents.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.save_asset_version!-Tuple{DataStore, Asset, String, Union{Nothing, VersionNumber}}","page":"API","title":"AHRI_TRE.save_asset_version!","text":"save_asset_version!(store::DataStore, existing_asset::Asset, description::String, new_version::Union{VersionNumber,Nothing})\n\nSave a new version of an existing asset in the TRE datastore.\n\nstore: The DataStore object containing connection details for the datastore.\nexisting_asset: The existing Asset object for which to create a new version.\ndescription: A description or note for the new version.\nnew_version: An optional VersionNumber object specifying the new version numbers. If nothing, the patch number of the latest version will be incremented by 1.\n\nThis function will create and save a new AssetVersion for the existing asset.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.save_version!-Tuple{DataStore, AssetVersion}","page":"API","title":"AHRI_TRE.save_version!","text":"save_version!(store::DataStore, version::AssetVersion)::AssetVersion\n\nSave an AssetVersion object to the TRE datastore.\n\nstore: The DataStore object containing connection details for the datastore.\nversion: The AssetVersion object to save.\n\nIf the version is marked as latest, it will unset the is_latest flag on all other versions\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.savedataframe-Tuple{DBInterface.Connection, DataFrames.AbstractDataFrame, Any}","page":"API","title":"AHRI_TRE.savedataframe","text":"savedataframe(con::DBInterface.Connection, df::AbstractDataFrame, table)\n\nSave a DataFrame to a database table, the names of the dataframe columns should be identical to the table column names in the database\n\ncon: The database connection\ndf: The DataFrame to save\ntable: The name of the table to save the data into\nreturns: nothing\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.selectdataframe-Tuple{DBInterface.Connection, String, Vector{String}, Vector{String}, Union{Tuple, AbstractDict, NamedTuple, AbstractVector}}","page":"API","title":"AHRI_TRE.selectdataframe","text":"selectdataframe(conn::DBInterface.Connection, table::String, columns::Vector{String}, filter::Vector{String}, filtervalues::DBInterface.StatementParams)::AbstractDataFrame\n\nReturn a dataframe from a table, with 0 to n columns to filter on\n\nconn: The database connection\ntable: The name of the table to query\ncolumns: A vector of column names to select\nfilter: A vector of column names to filter on\nfiltervalues: A vector of values corresponding to the filter columns\nreturns: A DataFrame containing the query results\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.set_version-Tuple{AssetVersion, Int64, Int64, Int64}","page":"API","title":"AHRI_TRE.set_version","text":"set_version(assetverion::AssetVersion, major::Int, minor::Int, patch::Int)::AssetVersion\n\nSet the version numbers of an AssetVersion object.\n\nassetversion: The AssetVersion object to update.    \nmajor: The major version number.\nminor: The minor version number.\npatch: The patch version number.\n\nReturns the updated AssetVersion object.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.set_version-Tuple{AssetVersion, VersionNumber}","page":"API","title":"AHRI_TRE.set_version","text":"set_version(assetverion::AssetVersion, version::VersionNumber)::AssetVersion\n\nSet the version numbers of an AssetVersion object using a VersionNumber object.\n\nassetversion: The AssetVersion object to update.    \nversion: The VersionNumber object containing major, minor, and patch numbers.\n\nReturns the updated AssetVersion object.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.sha256_digest_hex-Tuple{AbstractString}","page":"API","title":"AHRI_TRE.sha256_digest_hex","text":"sha256_digest_hex(path::AbstractString) -> String\n\nCompute the SHA-256 (SHA2-256) digest of a file and return it as a lowercase hex string.\n\npath: Path to the file to hash.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.table_exists-Tuple{Any, AbstractString, DatabaseFlavour}","page":"API","title":"AHRI_TRE.table_exists","text":"table_exists(conn, table_name::AbstractString, flavour::DatabaseFlavour) -> Bool\n\nCheck if a table exists in the database.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.table_has_primary_key-Tuple{Any, AbstractString, AbstractString, DatabaseFlavour}","page":"API","title":"AHRI_TRE.table_has_primary_key","text":"table_has_primary_key(conn, table_name::AbstractString, column_name::AbstractString, flavour::DatabaseFlavour) -> Bool\n\nCheck if the specified column is the primary key of the table.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.to_ncname-Tuple{AbstractString}","page":"API","title":"AHRI_TRE.to_ncname","text":"to_ncname(s::AbstractString; replacement=\"_\", prefix=\"_\", avoid_reserved=true) -> String\n\nConvert s into a valid NCName:\n\nReplaces any invalid char with replacement (default _).\nIf the first char is invalid, prepends prefix (default _).\nRemoves/condenses repeated replacements.\nReplaces : with replacement.\nOptionally avoids names starting with 'xml' (case-insensitive) by prepending prefix.\nIf strict=true, disallows - and . in names (replaces them too).\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.transaction_begin-Tuple{DBInterface.Connection}","page":"API","title":"AHRI_TRE.transaction_begin","text":"transaction_begin(conn::DBInterface.Connection)\n\nBegin a transaction on the specified DBInterface.Connection.\n\n'conn' is the DBInterface.Connection object representing the database connection.\n\nReturns nothing.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.transaction_begin-Tuple{DataStore}","page":"API","title":"AHRI_TRE.transaction_begin","text":"transaction_begin(store::DataStore; on_lake::Bool=false)\n\nBegin a transaction on the specified DataStore or its lake connection.\n\n'store' is the DataStore object containing the database connection.\n'on_lake' indicates whether to use the lake connection (true) or the main store connection (false).\n\nIf 'onlake' is true, it begins a transaction on the lake connection. If 'onlake' is false, it begins a transaction on the main data store connection. Returns nothing.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.transaction_commit-Tuple{DBInterface.Connection}","page":"API","title":"AHRI_TRE.transaction_commit","text":"transaction_commit(conn::DBInterface.Connection; on_lake::Bool=false)\n\nCommit a transaction on the specified DBInterface.Connection.\n\n'conn' is the DBInterface.Connection object representing the database connection.\n\nReturns nothing.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.transaction_commit-Tuple{DataStore}","page":"API","title":"AHRI_TRE.transaction_commit","text":"transaction_commit(store::DataStore; on_lake::Bool=false)\n\nCommit a transaction on the specified DataStore or its lake connection.\n\n'store' is the DataStore object containing the database connection.\n'on_lake' indicates whether to use the lake connection (true) or the main store connection (false).\n\nIf 'onlake' is true, it commits the transaction on the lake connection. If 'onlake' is false, it commits the transaction on the main data store connection. Returns nothing.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.transaction_rollback-Tuple{DBInterface.Connection}","page":"API","title":"AHRI_TRE.transaction_rollback","text":"transaction_rollback(conn::DBInterface.Connection; on_lake::Bool=false)\n\nRollback a transaction on the specified DBInterface.Connection.\n\n'conn' is the DBInterface.Connection object representing the database connection.\n\nReturns nothing.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.transaction_rollback-Tuple{DataStore}","page":"API","title":"AHRI_TRE.transaction_rollback","text":"transaction_rollback(store::DataStore; on_lake::Bool=false)\n\nRollback a transaction on the specified DataStore or its lake connection.\n\n'store' is the DataStore object containing the database connection.\n'on_lake' indicates whether to use the lake connection (true) or the main store connection (false).\n\nIf 'onlake' is true, it rolls back the transaction on the lake connection. If 'onlake' is false, it rolls back the transaction on the main data store connection. Returns nothing.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.transform_eav_to_table!-Tuple{DataStore, DataFile, DataSet}","page":"API","title":"AHRI_TRE.transform_eav_to_table!","text":"transform_eav_to_table!(store::DataStore, datafile::DataFile, dataset::DataSet)::Nothing\n\nTransform an EAV (Entity-Attribute-Value) data file into a table in the TRE lake.\n\n'store' is the DataStore object containing the database connection.\n'datafile' is the DataFile object representing the EAV data file.\n'dataset' is the DataSet object representing the target dataset.\n'convert' is a boolean flag indicating whether to convert the output table to the value_types defined in the dataset.\n\nThis function creates a new table in the TRE lake by pivoting the EAV data into a wide format. It aggregates multiple values for the same field per record into a single column. The table name is derived from the dataset's asset name. This function assumes the EAV data is stored in a csv table with columns: record, field_name, and value.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.tre_type_to_duckdb_sql-Tuple{Int64}","page":"API","title":"AHRI_TRE.tre_type_to_duckdb_sql","text":"tre_type_to_duckdb_sql(value_type_id::Int)::String\n\nMap TRE variable type IDs to DuckDB SQL data types.\n\n'valuetypeid' is the TRE variable type ID. \n\nThis function returns the corresponding DuckDB SQL data type as a string.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.updatevalues-Tuple{DBInterface.Connection, Vararg{Any, 5}}","page":"API","title":"AHRI_TRE.updatevalues","text":"updatevalues(conn::DBInterface.Connection, table, condition_column, condition_value, columns, values)\n\nUpdate value of column given conditionvalue in conditioncolumn\n\nconn: The database connection\ntable: The name of the table to update\ncondition_column: The name of the column to filter on\ncondition_value: The value to filter on\ncolumns: A vector of column names to update\nvalues: A vector of values corresponding to the columns to update\nreturns: nothing\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.updatevariable_vocabulary-Tuple{DBInterface.Connection, Any, Any, Any}","page":"API","title":"AHRI_TRE.updatevariable_vocabulary","text":"updatevariable_vocabulary(conn::DBInterface.Connection, name, domain_id, vocabulary_id)\n\nUpdate variable vocabulary\n\nconn: The database connection\nname: The name of the variable (supports SQL LIKE patterns)\ndomain_id: The domain ID of the variable\nvocabulary_id: The new vocabulary ID to set\nreturns: nothing\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.verify_sha256_digest-Tuple{AbstractString, AbstractString}","page":"API","title":"AHRI_TRE.verify_sha256_digest","text":"verify_sha256_digest(path::AbstractString, expected_hex::AbstractString) -> Bool\n\nCheck whether the file's SHA-256 digest matches the expected hex string. Returns true on match, false otherwise.\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.vocabulary_items-Tuple{Any}","page":"API","title":"AHRI_TRE.vocabulary_items","text":"vocabulary_items(items) -> Vector{VocabularyItem}\n\nConvert a vector of REDCap choice items (as NamedTuples with keys :value, :code, :description) into a vector of VocabularyItem structs.\n\nNotes:\n\nvocabulary_id is set to 0 as a placeholder; it should be populated when the vocabulary is persisted (e.g. via ensure_vocabulary!).\n\n\n\n\n\n","category":"method"},{"location":"api/#AHRI_TRE.wrap_query_for_metadata-Tuple{AbstractString, DatabaseFlavour}","page":"API","title":"AHRI_TRE.wrap_query_for_metadata","text":"wrap_query_for_metadata(sql::AbstractString, flavour::DatabaseFlavour) -> String\n\nWrap the query to limit results for metadata extraction.\n\n\n\n\n\n","category":"method"},{"location":"introduction/#Introduction","page":"Introduction","title":"Introduction","text":"This package creates and ingest data for the AHRI Trusted Research Environment into a PostgreSQL and ducklake managed data lake.\n\nData ingestion is specific to a study, where a study is any research study collecting data about entities and the relationships between these entities.\n\nAHRI_TRE can import data directly from a REDCap project and create the necessary metadata to describe the data in the project.","category":"section"},{"location":"introduction/#Database-Structure","page":"Introduction","title":"Database Structure","text":"The conceptual model of the AHRI_TRE is shown in Figure 1. (Image: Fig 1: AHRI-TRE Conceptual Model)","category":"section"},{"location":"introduction/#Studies","page":"Introduction","title":"Studies","text":"A study is described in the following tables:\n\nTable Name Description\nstudies A research study collecting data about entities and the relationships between them\nstudy_types Record different types of studies contributing data to the TRE\nstudy_access Access control linking users to studies and used in row level security\nstudy_domains Associate studies with domains","category":"section"},{"location":"introduction/#Entities","page":"Introduction","title":"Entities","text":"The entities and the relationships between them are described in the following tables:\n\nTable Name Description\nentities Entities such as individuals, households, etc. and links to public ontologies\nentityrelations Relationships between entities, such as household membership, and links to public ontologies\nentity_instances Specific instances of entities in a study, allows linking of instances, e.g. a person to data assets containing data about that person\nrelation_instances Instances of entity relationships, e.g. the membership of a specific person to an instance of a household","category":"section"},{"location":"introduction/#Assets","page":"Introduction","title":"Assets","text":"The data assets containing the data collected by a study are described in the following tables:\n\nTable Name Description\nassets Digital assets such as datasets and files contained in the data lake\ndataassetentities Link assets to entity instances, to track instances associated with an asset\nasset_versions Used to track different versions of assets\ndatafiles A specific version of a file (binary large object(BLOB)) stored in the data lake\ndataset An asset version of tabular dataset managed by ducklake in the data lake\ndataset_variables The variables associated with the columns in the dataset","category":"section"},{"location":"introduction/#Transformations","page":"Introduction","title":"Transformations","text":"Transformations tracks the process of ingesting, transforming and exporting data from the TRE. This is described in the following tables:\n\nTable Name Description\ntransformations Documents the transformation (ingest, transform, entity instance generation, exporting, and placement in a data repository)\ntransformation_inputs The input data asset/s used by the transformation\ntransformation_outputs The data asset/s produced by the transformation","category":"section"},{"location":"introduction/#Variables","page":"Introduction","title":"Variables","text":"The variables representing the data contained in datasets, is described by the following tables:\n\nTable Name Description\ndomains Variable names are unique within a domain\nvariables Documents a variable\nvalue_types Representing the different datatypes, variables can assume\nvocabularies The values a categorical variables can assume, are contained in a vocabulary\nvocabulary_items The individual categories (codes) in a vocabulary\nvocabulary_mapping The items of one vocabulary can be mapped to those in another vocabulary","category":"section"},{"location":"#AHRI_TRE.jl","page":"Home","title":"AHRI_TRE.jl","text":"Documentation for AHRI_TRE.jl","category":"section"}]
}
